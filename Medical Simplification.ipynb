{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"52660196a8124f1d9e13976ad5ac4203":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f218075168e84cd89cf889d755e165fd","IPY_MODEL_da45140575304c03a00e3219caa2b839","IPY_MODEL_be25ad12801b4eb4885d2843a9ff20d0"],"layout":"IPY_MODEL_433a2d27dfbd43f98ee956180eb907ff"}},"f218075168e84cd89cf889d755e165fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ca93a8ae8c441d78fb35e2651fcd1c1","placeholder":"​","style":"IPY_MODEL_b7ef11b413724fa48f8d2d57f2f89738","value":"tokenizer_config.json: 100%"}},"da45140575304c03a00e3219caa2b839":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd8dd7f02dfa4b2f827a50893b26185c","max":53297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c150b96c7e54d0fa401889120ab74bf","value":53297}},"be25ad12801b4eb4885d2843a9ff20d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efd76514580241e197971746100ad9ae","placeholder":"​","style":"IPY_MODEL_c16cdd17238c4e4c88915663be4f7d13","value":" 53.3k/53.3k [00:00&lt;00:00, 5.03MB/s]"}},"433a2d27dfbd43f98ee956180eb907ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ca93a8ae8c441d78fb35e2651fcd1c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ef11b413724fa48f8d2d57f2f89738":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd8dd7f02dfa4b2f827a50893b26185c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c150b96c7e54d0fa401889120ab74bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efd76514580241e197971746100ad9ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c16cdd17238c4e4c88915663be4f7d13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf9ef4fd8cb341238fc1333d3d8198a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c72a00f768ea45f89f86da180a9e062a","IPY_MODEL_6ecafbda92ca4a46b68c22a07645af75","IPY_MODEL_5d2d786cd2f544f0a86a839e696f8095"],"layout":"IPY_MODEL_77eb3e9ec0d04eaa8384a98f2e5b773c"}},"c72a00f768ea45f89f86da180a9e062a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b3646327ad47559515e47d7191a5f0","placeholder":"​","style":"IPY_MODEL_e74e71ca920f4d6ab31391ba47169a9f","value":"tokenizer.json: 100%"}},"6ecafbda92ca4a46b68c22a07645af75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a241aaa04c9c4b94a67290c9593a1c7f","max":9085955,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf69a736909c4645b32a5f843bf5ec17","value":9085955}},"5d2d786cd2f544f0a86a839e696f8095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_411e700675334403a6832ad79313bdb7","placeholder":"​","style":"IPY_MODEL_3af656ea00654e989dbe6628c6279631","value":" 9.09M/9.09M [00:01&lt;00:00, 8.00MB/s]"}},"77eb3e9ec0d04eaa8384a98f2e5b773c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b3646327ad47559515e47d7191a5f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e74e71ca920f4d6ab31391ba47169a9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a241aaa04c9c4b94a67290c9593a1c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf69a736909c4645b32a5f843bf5ec17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"411e700675334403a6832ad79313bdb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af656ea00654e989dbe6628c6279631":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd18f0a6f2fa461cbfd2846f5febebf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44c09ea8c5504d3f91bf62ea4736c3cd","IPY_MODEL_586d0134598b4ca4956b84fd3fe0269a","IPY_MODEL_1ed0d727852b4d2789a652c682561a29"],"layout":"IPY_MODEL_88eda1e1bf174b36addf386eb4d4f544"}},"44c09ea8c5504d3f91bf62ea4736c3cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_682150ce061243b596474abd2113fb36","placeholder":"​","style":"IPY_MODEL_2d0f83fe885e4508ad2e761f91480462","value":"special_tokens_map.json: 100%"}},"586d0134598b4ca4956b84fd3fe0269a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41319df3a26d415ba15e8433e5a9bf4b","max":462,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec03fedf1a32455ba570c94050c3fd51","value":462}},"1ed0d727852b4d2789a652c682561a29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d061bdad50d24f24a3c7db25d4bfb804","placeholder":"​","style":"IPY_MODEL_b660452577dd4b229d365ff18548d774","value":" 462/462 [00:00&lt;00:00, 62.7kB/s]"}},"88eda1e1bf174b36addf386eb4d4f544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"682150ce061243b596474abd2113fb36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0f83fe885e4508ad2e761f91480462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41319df3a26d415ba15e8433e5a9bf4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec03fedf1a32455ba570c94050c3fd51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d061bdad50d24f24a3c7db25d4bfb804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b660452577dd4b229d365ff18548d774":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c4769cc973d47dc9234bc2d2de947e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87d85c14cf194b42866d6073b4334fd3","IPY_MODEL_bf8955c993fd4ff7babe6afb6b46f016","IPY_MODEL_8868784d573742d7943f0e167e107e6e"],"layout":"IPY_MODEL_4ef489c55c8e48a3b8473ccca4b7cc4e"}},"87d85c14cf194b42866d6073b4334fd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be07c4ecd663421c94aaea2ee6a5ea4d","placeholder":"​","style":"IPY_MODEL_844f2eb29db047dd8e661832459f4f78","value":"config.json: 100%"}},"bf8955c993fd4ff7babe6afb6b46f016":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ee3dc7bd5434de7b96ada01661702f4","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebfb21b3eebd46fbbf54989c74a1364f","value":772}},"8868784d573742d7943f0e167e107e6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9577ab32417144d88e2441ec9a9414f4","placeholder":"​","style":"IPY_MODEL_7c901dbaf9b64c68aaa038cddb2064f5","value":" 772/772 [00:00&lt;00:00, 107kB/s]"}},"4ef489c55c8e48a3b8473ccca4b7cc4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be07c4ecd663421c94aaea2ee6a5ea4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844f2eb29db047dd8e661832459f4f78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ee3dc7bd5434de7b96ada01661702f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebfb21b3eebd46fbbf54989c74a1364f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9577ab32417144d88e2441ec9a9414f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c901dbaf9b64c68aaa038cddb2064f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd69d49269404e50a8527b0d9d696707":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f7ad5a881cf48f897619468f2f8f330","IPY_MODEL_387979331eb4441787c2d8bf753fca15","IPY_MODEL_c8122c2a122b43e1a884be8c1cba9146"],"layout":"IPY_MODEL_c340e9a5da4c45ad93de86ec9472ef4c"}},"6f7ad5a881cf48f897619468f2f8f330":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_befb6abb2cfd498bbbeebbc7a38b066f","placeholder":"​","style":"IPY_MODEL_5fcfc7a705614447af906108c2d7fade","value":"model.safetensors.index.json: 100%"}},"387979331eb4441787c2d8bf753fca15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5edbf390635e4935af195adf4f950649","max":22771,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd9f2e5d15db4bc1bf86fc488d49d7de","value":22771}},"c8122c2a122b43e1a884be8c1cba9146":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c968f13e6898408fb253455af3a32b1f","placeholder":"​","style":"IPY_MODEL_10e004b7d41742178bf530f85ce00f31","value":" 22.8k/22.8k [00:00&lt;00:00, 3.07MB/s]"}},"c340e9a5da4c45ad93de86ec9472ef4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"befb6abb2cfd498bbbeebbc7a38b066f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fcfc7a705614447af906108c2d7fade":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5edbf390635e4935af195adf4f950649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd9f2e5d15db4bc1bf86fc488d49d7de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c968f13e6898408fb253455af3a32b1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10e004b7d41742178bf530f85ce00f31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286d7da9cf9447729160827ed4ee94ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_369e46356020459396242dd068df1b3b","IPY_MODEL_b07259c855ce4034a5e600ef3fd9a8b2","IPY_MODEL_52a16e828eb546d6af33830d7d2cb24f"],"layout":"IPY_MODEL_e66e792b10dd4ccfb14eee2d175b9e98"}},"369e46356020459396242dd068df1b3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7fb6271d4b741a6b2befb67578632da","placeholder":"​","style":"IPY_MODEL_92aa4e8ca27a40a48f6f107657a570d1","value":"Downloading shards: 100%"}},"b07259c855ce4034a5e600ef3fd9a8b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_366cf10bb030431cba77217be8c15083","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1642ebb178d74e54b77714d8eefb1a61","value":2}},"52a16e828eb546d6af33830d7d2cb24f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df3d10b9ce440c1b723a195922e45a8","placeholder":"​","style":"IPY_MODEL_f82d430b4fc14897a9fe8c6a75d5b0a1","value":" 2/2 [01:15&lt;00:00, 35.46s/it]"}},"e66e792b10dd4ccfb14eee2d175b9e98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7fb6271d4b741a6b2befb67578632da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92aa4e8ca27a40a48f6f107657a570d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"366cf10bb030431cba77217be8c15083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1642ebb178d74e54b77714d8eefb1a61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3df3d10b9ce440c1b723a195922e45a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82d430b4fc14897a9fe8c6a75d5b0a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"294225166f0c41739d8fe17d58e9e455":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38fefa4247b644c984377fb6a878c735","IPY_MODEL_f31ce6650ab64490b638e1b675a996e8","IPY_MODEL_1ef25d7ebd1e449786f2eb0558f84a03"],"layout":"IPY_MODEL_7a088b7edbff4ab991269f41a4a3c070"}},"38fefa4247b644c984377fb6a878c735":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a745cadaf74b466f90533d93419f3c41","placeholder":"​","style":"IPY_MODEL_5b993d9f84974e67b86504e9cf9b1cab","value":"model-00001-of-00002.safetensors: 100%"}},"f31ce6650ab64490b638e1b675a996e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e1be065b9747dd8bb859554db3f1fb","max":9976501400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3dcf676d85b4488bbf8bcb7e0a9f61c","value":9976501400}},"1ef25d7ebd1e449786f2eb0558f84a03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc30708647d4547a9ef57fba81dedc0","placeholder":"​","style":"IPY_MODEL_0a041860dc96431d8a3fbdcf292704ad","value":" 9.98G/9.98G [00:50&lt;00:00, 307MB/s]"}},"7a088b7edbff4ab991269f41a4a3c070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a745cadaf74b466f90533d93419f3c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b993d9f84974e67b86504e9cf9b1cab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15e1be065b9747dd8bb859554db3f1fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3dcf676d85b4488bbf8bcb7e0a9f61c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8dc30708647d4547a9ef57fba81dedc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a041860dc96431d8a3fbdcf292704ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443aee8d45104984bdf39a926f641c82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6547c57429d148e384a3ba8d47e3af35","IPY_MODEL_86ae76fec0b148cc8c136373e62d416e","IPY_MODEL_cde3a635f99a45d8a621188edf4702de"],"layout":"IPY_MODEL_5da4035bfd7d4fe989e5a01cba922651"}},"6547c57429d148e384a3ba8d47e3af35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d3207912adf42cdaf3d69f7d58e6dfe","placeholder":"​","style":"IPY_MODEL_2b934b9aa5f141da81ff3030e30fd0e3","value":"model-00002-of-00002.safetensors: 100%"}},"86ae76fec0b148cc8c136373e62d416e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e608989d7e84bf9aa759785fa223d46","max":6084055000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3a24d4b05c5427ba2e672528a656cd2","value":6084055000}},"cde3a635f99a45d8a621188edf4702de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e98800d2b34c279ce761999d3ce154","placeholder":"​","style":"IPY_MODEL_6818cebe40d54e7e90fa1ad9ad9c1aa9","value":" 6.08G/6.08G [00:24&lt;00:00, 275MB/s]"}},"5da4035bfd7d4fe989e5a01cba922651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d3207912adf42cdaf3d69f7d58e6dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b934b9aa5f141da81ff3030e30fd0e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e608989d7e84bf9aa759785fa223d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3a24d4b05c5427ba2e672528a656cd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e98800d2b34c279ce761999d3ce154":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6818cebe40d54e7e90fa1ad9ad9c1aa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dd80dbe6ce547ee9687f870cc9b298e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79495ca98d1b4583a0c6a23e08b68900","IPY_MODEL_7b018da084504db68f60b2de70b6fd2e","IPY_MODEL_b2f4be5871184cf4964533ccfb27f9c9"],"layout":"IPY_MODEL_138493bcfab6421aa6ceed92c9880937"}},"79495ca98d1b4583a0c6a23e08b68900":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d9cd7c72ed445692218b9c50e164af","placeholder":"​","style":"IPY_MODEL_8651af440faf4fc999f546d232940736","value":"Loading checkpoint shards: 100%"}},"7b018da084504db68f60b2de70b6fd2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90625ecb8b1f47c48203207400b6bfaf","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cf5cbfc5737496d8edfd653f23e3831","value":2}},"b2f4be5871184cf4964533ccfb27f9c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db5feba79f14493c8bacc6766ad670d9","placeholder":"​","style":"IPY_MODEL_9a46de8476f24c1792bdd6cd2d7b73c5","value":" 2/2 [00:06&lt;00:00,  3.18s/it]"}},"138493bcfab6421aa6ceed92c9880937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d9cd7c72ed445692218b9c50e164af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8651af440faf4fc999f546d232940736":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90625ecb8b1f47c48203207400b6bfaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf5cbfc5737496d8edfd653f23e3831":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db5feba79f14493c8bacc6766ad670d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a46de8476f24c1792bdd6cd2d7b73c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f79f12d7e0914c2fbbfb59b2683dae96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3963e87a4ee41c6bb2a62353ba7622e","IPY_MODEL_75477a0564204d198d87337df62b3043","IPY_MODEL_8e254fc381e04813ab8be452db42da5b"],"layout":"IPY_MODEL_ed337bcfcacd4caa8cb85742e44ff02d"}},"c3963e87a4ee41c6bb2a62353ba7622e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1a20112bed46578369d886e2b6dc89","placeholder":"​","style":"IPY_MODEL_b755f66d312744d88a3901f12cf3ab5e","value":"tokenizer_config.json: 100%"}},"75477a0564204d198d87337df62b3043":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29cba5d235b94f0a83ca93c50cbe145b","max":53297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41f44a11dc2d41488936ddf87720b2d9","value":53297}},"8e254fc381e04813ab8be452db42da5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a802a8d831f4a179a9210935d2103d8","placeholder":"​","style":"IPY_MODEL_065521a754d64da6b12fbb75004e5163","value":" 53.3k/53.3k [00:00&lt;00:00, 4.46MB/s]"}},"ed337bcfcacd4caa8cb85742e44ff02d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1a20112bed46578369d886e2b6dc89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b755f66d312744d88a3901f12cf3ab5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29cba5d235b94f0a83ca93c50cbe145b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f44a11dc2d41488936ddf87720b2d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a802a8d831f4a179a9210935d2103d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"065521a754d64da6b12fbb75004e5163":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a69b8dcf416541a69d9460e8486777e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64d24888e4b94dc9bf059cf8be0f754e","IPY_MODEL_4bc14f59137e41369d29027adbe40df4","IPY_MODEL_3f0589fd486646c2aa59e115604d56c7"],"layout":"IPY_MODEL_4e5349e35db843b3aa08a7670dc8fd73"}},"64d24888e4b94dc9bf059cf8be0f754e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a963878ebf1a42a5bd49b78c25aab78b","placeholder":"​","style":"IPY_MODEL_5bb4d21fb63a43ec989cf073b5fe554e","value":"tokenizer.json: 100%"}},"4bc14f59137e41369d29027adbe40df4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3718144bec7a424d823b012f01ca7e60","max":9085955,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e90a3dfa9624ab9b5fc18359bb0931b","value":9085955}},"3f0589fd486646c2aa59e115604d56c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2b1a6400b34ed9b6be0e41faa0e426","placeholder":"​","style":"IPY_MODEL_231d0b572d274f0980adf12bab460a49","value":" 9.09M/9.09M [00:00&lt;00:00, 26.5MB/s]"}},"4e5349e35db843b3aa08a7670dc8fd73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a963878ebf1a42a5bd49b78c25aab78b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb4d21fb63a43ec989cf073b5fe554e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3718144bec7a424d823b012f01ca7e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e90a3dfa9624ab9b5fc18359bb0931b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d2b1a6400b34ed9b6be0e41faa0e426":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"231d0b572d274f0980adf12bab460a49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da588342ae6d410e928a0520ac918abe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d5ab4fdfb4f48af95ae22ec5e4b2da5","IPY_MODEL_1df1182331194beea1ab852ce3f08cfc","IPY_MODEL_54df150386f24d2ea7bd7f3c26c5008d"],"layout":"IPY_MODEL_c12182951c934c5b9af34f2017e0a8d1"}},"2d5ab4fdfb4f48af95ae22ec5e4b2da5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15140c13777e43008a3715cb10cb2f9d","placeholder":"​","style":"IPY_MODEL_3b4262b22f4b4e058bfebc7dd04bdfff","value":"special_tokens_map.json: 100%"}},"1df1182331194beea1ab852ce3f08cfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_976ddb009c2d4314a0efce740c1e610a","max":462,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a47a237689d24d3fbe517ccf2ca6c794","value":462}},"54df150386f24d2ea7bd7f3c26c5008d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_553837e9363242bab9bb42c41967aadb","placeholder":"​","style":"IPY_MODEL_dc66de4a5ef546ee871d1cb17cd5af17","value":" 462/462 [00:00&lt;00:00, 60.0kB/s]"}},"c12182951c934c5b9af34f2017e0a8d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15140c13777e43008a3715cb10cb2f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b4262b22f4b4e058bfebc7dd04bdfff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"976ddb009c2d4314a0efce740c1e610a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a47a237689d24d3fbe517ccf2ca6c794":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"553837e9363242bab9bb42c41967aadb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc66de4a5ef546ee871d1cb17cd5af17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7be0c3f848bf4b5cb9e3ac4dded5de64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5d2ac39bb74479db8030ef28008c8eb","IPY_MODEL_0637f625cd34418dbb24f2dcadfaefa2","IPY_MODEL_b262a4271ba749bdafa02f8760a5623a"],"layout":"IPY_MODEL_94242b72504341a59116f50ca9e2ef8c"}},"c5d2ac39bb74479db8030ef28008c8eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2b95f8e5dcf44008246d50b291bb0c6","placeholder":"​","style":"IPY_MODEL_fbbf9ec9cca64a509c8bbdbdd5ed8367","value":"config.json: 100%"}},"0637f625cd34418dbb24f2dcadfaefa2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e989990463b4139a5029cbfd0c9bd89","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91fcf4301b3b4ecbb3f01424e2b36d04","value":772}},"b262a4271ba749bdafa02f8760a5623a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_452e6f2d1e6a49ed9f77c9ab4d669d92","placeholder":"​","style":"IPY_MODEL_ddeaf3fef16749b3b973911ad8c9ada0","value":" 772/772 [00:00&lt;00:00, 87.5kB/s]"}},"94242b72504341a59116f50ca9e2ef8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2b95f8e5dcf44008246d50b291bb0c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbbf9ec9cca64a509c8bbdbdd5ed8367":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e989990463b4139a5029cbfd0c9bd89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91fcf4301b3b4ecbb3f01424e2b36d04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"452e6f2d1e6a49ed9f77c9ab4d669d92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddeaf3fef16749b3b973911ad8c9ada0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"641ff5c9a46c4e41bb85a543561c085c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf7f4f945c0a423da5ac4d435751b49f","IPY_MODEL_7f6e77420bc14879afc7386960b84186","IPY_MODEL_c48fdcf895bb4c87afc1cbf46bc36ba0"],"layout":"IPY_MODEL_495c78c7bf514e929a56636cee56e0c4"}},"bf7f4f945c0a423da5ac4d435751b49f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03c032865c3049f0b287fd4fc5e1092d","placeholder":"​","style":"IPY_MODEL_1896cd889335437f9464145a709bf927","value":"model.safetensors.index.json: 100%"}},"7f6e77420bc14879afc7386960b84186":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f973ad7145a4c5295e75c69723a4d62","max":22771,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d49be462fda443197cd91dca7019bfe","value":22771}},"c48fdcf895bb4c87afc1cbf46bc36ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_742c7f91fb424b9d8206f87b6bd8fce0","placeholder":"​","style":"IPY_MODEL_bbb32f53e0f2434fb18274efd1ef3088","value":" 22.8k/22.8k [00:00&lt;00:00, 2.82MB/s]"}},"495c78c7bf514e929a56636cee56e0c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c032865c3049f0b287fd4fc5e1092d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1896cd889335437f9464145a709bf927":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f973ad7145a4c5295e75c69723a4d62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d49be462fda443197cd91dca7019bfe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"742c7f91fb424b9d8206f87b6bd8fce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbb32f53e0f2434fb18274efd1ef3088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"411fccda502c4dd5937bca93dee3641e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28e3c5a752ba4febbfb94cfd2603a9b2","IPY_MODEL_503c21dc84f34ab9af5edc3e2c690378","IPY_MODEL_a0e444ba8a8c436cbe1bf4aded24c4ae"],"layout":"IPY_MODEL_092946569b094270ad534c0038948378"}},"28e3c5a752ba4febbfb94cfd2603a9b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5d3ffe492024e28a2122e63df527e47","placeholder":"​","style":"IPY_MODEL_111f2e7bc141402f9a4ca03682a057c8","value":"Downloading shards: 100%"}},"503c21dc84f34ab9af5edc3e2c690378":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b7277cb733c4f2794f17fe91333f562","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c00cfbc38a5246b38cbfae0ba9bd0ac6","value":2}},"a0e444ba8a8c436cbe1bf4aded24c4ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc26085621a949c1a2e7cb4c68571340","placeholder":"​","style":"IPY_MODEL_98759d876df94393a8fdb48205d219df","value":" 2/2 [01:24&lt;00:00, 40.43s/it]"}},"092946569b094270ad534c0038948378":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5d3ffe492024e28a2122e63df527e47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"111f2e7bc141402f9a4ca03682a057c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b7277cb733c4f2794f17fe91333f562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c00cfbc38a5246b38cbfae0ba9bd0ac6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc26085621a949c1a2e7cb4c68571340":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98759d876df94393a8fdb48205d219df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9ade09c1df84f5bad5f4b9f099fbfbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a888f0c73ac4e9d835219a6b56da733","IPY_MODEL_80d54a8125034b6a8165b31cca4efbfe","IPY_MODEL_c10f86cae96141eeb4dbd0313b6743ec"],"layout":"IPY_MODEL_5656341b0c1a477981ed6cb75639c78d"}},"0a888f0c73ac4e9d835219a6b56da733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df8c32f9e2442d0bbad2a0ee853ddad","placeholder":"​","style":"IPY_MODEL_60f34ad15540476a8880c980c9176bd6","value":"model-00001-of-00002.safetensors: 100%"}},"80d54a8125034b6a8165b31cca4efbfe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc3ed82d34464c7e9af47a7cd50fb4fd","max":9976501400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33ad4602552a4f8bbdcca983d77e9dd5","value":9976501400}},"c10f86cae96141eeb4dbd0313b6743ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6727b49957ce45f9ad15fd8c9419a195","placeholder":"​","style":"IPY_MODEL_2ce27d00e21240008a9e18e0825946db","value":" 9.98G/9.98G [00:50&lt;00:00, 377MB/s]"}},"5656341b0c1a477981ed6cb75639c78d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df8c32f9e2442d0bbad2a0ee853ddad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f34ad15540476a8880c980c9176bd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc3ed82d34464c7e9af47a7cd50fb4fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ad4602552a4f8bbdcca983d77e9dd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6727b49957ce45f9ad15fd8c9419a195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ce27d00e21240008a9e18e0825946db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dde1519a07941f88619f8c845af6398":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0ffe4220f8b4ef1a3ec5cf147825df6","IPY_MODEL_19369f65a55e4d2f82dac1b1a2409927","IPY_MODEL_4dd50c98cd014c6a8526d3957d020302"],"layout":"IPY_MODEL_cfa35fc61a3d4e5caf60371b48ff13b9"}},"d0ffe4220f8b4ef1a3ec5cf147825df6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7472237b2e684932a437a02b1d7a29c4","placeholder":"​","style":"IPY_MODEL_00c0dda3f1a14c68a88cdf54fa66aaf8","value":"model-00002-of-00002.safetensors: 100%"}},"19369f65a55e4d2f82dac1b1a2409927":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78c72825e78745a788e856c8b72dc1a2","max":6084055000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4070b5394dac41298735b0b2d58dbbc3","value":6084055000}},"4dd50c98cd014c6a8526d3957d020302":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bfb5732b8d84dd39c423d3208c62aa3","placeholder":"​","style":"IPY_MODEL_f9f74ed447ee4bebb0877e6a2704a901","value":" 6.08G/6.08G [00:32&lt;00:00, 283MB/s]"}},"cfa35fc61a3d4e5caf60371b48ff13b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7472237b2e684932a437a02b1d7a29c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00c0dda3f1a14c68a88cdf54fa66aaf8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78c72825e78745a788e856c8b72dc1a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4070b5394dac41298735b0b2d58dbbc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bfb5732b8d84dd39c423d3208c62aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f74ed447ee4bebb0877e6a2704a901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fec843c0f3ee45cda278f5e2a60bd0bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54898c91bc664da2a4863a6965b883d8","IPY_MODEL_7ccc05ecaeb4402ca30254dbd8bef4f8","IPY_MODEL_fed139af239b4bb1aa38a0791406f5c2"],"layout":"IPY_MODEL_7205ac3943e4428da06f4d43f27fc943"}},"54898c91bc664da2a4863a6965b883d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98d4bebb64274aa7982ec515de34b50a","placeholder":"​","style":"IPY_MODEL_0c4f3a82b36d4b80a19fefea4f0ad215","value":"Loading checkpoint shards: 100%"}},"7ccc05ecaeb4402ca30254dbd8bef4f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea1270e9e5b24b82a5763b4fbd1162ea","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f63189ec65a5447a968ec5f3b522aa90","value":2}},"fed139af239b4bb1aa38a0791406f5c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a49c0b9d8b894554ad21dc25dad0011b","placeholder":"​","style":"IPY_MODEL_3d7645d20377489586b09a6b1d53fe4e","value":" 2/2 [00:08&lt;00:00,  4.13s/it]"}},"7205ac3943e4428da06f4d43f27fc943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98d4bebb64274aa7982ec515de34b50a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c4f3a82b36d4b80a19fefea4f0ad215":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea1270e9e5b24b82a5763b4fbd1162ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f63189ec65a5447a968ec5f3b522aa90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a49c0b9d8b894554ad21dc25dad0011b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d7645d20377489586b09a6b1d53fe4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b07a8e234d4ee3a6d627efa946b780":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_baf153bc8a5846b39c1176dd86bdf61b","IPY_MODEL_0c52aab46c7242fb80277ec0138ca628","IPY_MODEL_551390bb37c0469988b6cbfdd797fb3f"],"layout":"IPY_MODEL_59a0f2548e364a12967b32caec063b4f"}},"baf153bc8a5846b39c1176dd86bdf61b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f948c01627d48b890ad649932fd81a4","placeholder":"​","style":"IPY_MODEL_1a5510b4b8ae45bcb63af12e89c5df2e","value":"100%"}},"0c52aab46c7242fb80277ec0138ca628":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd3502af869b4a3aa3242bfa78de67d8","max":213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fadd944a29a64f4b86f7a9a7e2eeed99","value":213}},"551390bb37c0469988b6cbfdd797fb3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ee44a9552d742e997004c15f5663e8f","placeholder":"​","style":"IPY_MODEL_1b44621528984cf993fcfec79e7a85cc","value":" 213/213 [18:52&lt;00:00,  5.30s/it]"}},"59a0f2548e364a12967b32caec063b4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f948c01627d48b890ad649932fd81a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a5510b4b8ae45bcb63af12e89c5df2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd3502af869b4a3aa3242bfa78de67d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fadd944a29a64f4b86f7a9a7e2eeed99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ee44a9552d742e997004c15f5663e8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b44621528984cf993fcfec79e7a85cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"956ff30ca6c74d29b2b6c32685293c06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ad8626f9da0459fb3db85fe6790922e","IPY_MODEL_f53a5e3022104af5b19c03909fac56b4","IPY_MODEL_8e41acc15294491999db3c0792dc7b1c"],"layout":"IPY_MODEL_2c7de76c7cac453cb1a056df04905ef5"}},"2ad8626f9da0459fb3db85fe6790922e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6b430360e4b41f688e300d11d9c4c7c","placeholder":"​","style":"IPY_MODEL_8c71f6cdd87e4788a99f2fa10f996c3f","value":" 35%"}},"f53a5e3022104af5b19c03909fac56b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f58b09eba9f456d8272015870eb8864","max":250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfb3670a13fb42cc9d1b1f523329e406","value":87}},"8e41acc15294491999db3c0792dc7b1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dc1c0aff4d34badb78e0ffdd84bf034","placeholder":"​","style":"IPY_MODEL_4974e882e0d34a2496548e1a71e8d7c7","value":" 87/250 [11:18&lt;18:37,  6.86s/it]"}},"2c7de76c7cac453cb1a056df04905ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6b430360e4b41f688e300d11d9c4c7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c71f6cdd87e4788a99f2fa10f996c3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f58b09eba9f456d8272015870eb8864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb3670a13fb42cc9d1b1f523329e406":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0dc1c0aff4d34badb78e0ffdd84bf034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4974e882e0d34a2496548e1a71e8d7c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec9442077ad34917a884992411bdecd3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93fbbc99b2f34df4a008d65704c46e6a","IPY_MODEL_498ab8e53e9d4b4b9cb041be82e51345","IPY_MODEL_f221879e61044262b53969e283974453"],"layout":"IPY_MODEL_3edbabc9d37143f7a9e22783740e29b7"}},"93fbbc99b2f34df4a008d65704c46e6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76b7f51246524517956d23441b7763e7","placeholder":"​","style":"IPY_MODEL_c745a752867c4fc49830b762e6ea9f8c","value":"Loading checkpoint shards: 100%"}},"498ab8e53e9d4b4b9cb041be82e51345":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_286bf0d22fe0443fb6a08661abfb4ecb","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40a274f6a4294d2b9918c234f265d6f3","value":2}},"f221879e61044262b53969e283974453":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae36d7ac8444e5dab5e62bb92cae25b","placeholder":"​","style":"IPY_MODEL_7ba8ec8871574e9292ca67fcb13f2c06","value":" 2/2 [00:08&lt;00:00,  4.18s/it]"}},"3edbabc9d37143f7a9e22783740e29b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b7f51246524517956d23441b7763e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c745a752867c4fc49830b762e6ea9f8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286bf0d22fe0443fb6a08661abfb4ecb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a274f6a4294d2b9918c234f265d6f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fae36d7ac8444e5dab5e62bb92cae25b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ba8ec8871574e9292ca67fcb13f2c06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea2b0267d09a4aecb863a1803b0f2daa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd8242d77c2547a285e8a0cc1a9bf35f","IPY_MODEL_6b524d5df3d04d01ac984122fbd1a039","IPY_MODEL_6ee60c4fb94946719594a1a62eba1013"],"layout":"IPY_MODEL_080b0d44533b4c00bfb7a8b19daac6fd"}},"cd8242d77c2547a285e8a0cc1a9bf35f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d9e2ab4394c47048a90442f76379e46","placeholder":"​","style":"IPY_MODEL_24ebe58e3c114f6e932db33396bf526c","value":"⇢ generating: 100%"}},"6b524d5df3d04d01ac984122fbd1a039":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_22aeea56a4784868b43d2346370507cb","max":1697,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86e67f26730e49689457f0c0e95d0974","value":1697}},"6ee60c4fb94946719594a1a62eba1013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bbe445291b44fa7b206ed3284545839","placeholder":"​","style":"IPY_MODEL_889434f0d28e4011b9f492d12c17aebc","value":" 1697/1697 [14:10&lt;00:00,  1.29it/s]"}},"080b0d44533b4c00bfb7a8b19daac6fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d9e2ab4394c47048a90442f76379e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24ebe58e3c114f6e932db33396bf526c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22aeea56a4784868b43d2346370507cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86e67f26730e49689457f0c0e95d0974":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bbe445291b44fa7b206ed3284545839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"889434f0d28e4011b9f492d12c17aebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0788dd9dbd5644a8b8d6e81036a8a875":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e3e6c2b8ac14193a5353dcfe9adf8ba","IPY_MODEL_3133e7a7776d43dfa2dd0bd9bcf05304","IPY_MODEL_3dc8bdbafeba4a72913a87dc13e72410"],"layout":"IPY_MODEL_816604c6ffdf46d2b0509a9a7ad27acb"}},"5e3e6c2b8ac14193a5353dcfe9adf8ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80eb754c36ad4caa9a84e320fbbc6526","placeholder":"​","style":"IPY_MODEL_285d3bbe0fee4173a7643467e0f92187","value":"⇢ generating:  38%"}},"3133e7a7776d43dfa2dd0bd9bcf05304":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2ce06e6e8864b18832d0cfa0ef3dcb5","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25b05837db304a2da5bffb35179adbfa","value":188}},"3dc8bdbafeba4a72913a87dc13e72410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8d5ef5dfd5d47b2873ac64e425abb72","placeholder":"​","style":"IPY_MODEL_8111fee504ec43799395dc783d2069eb","value":" 188/500 [33:54&lt;1:01:49, 11.89s/it]"}},"816604c6ffdf46d2b0509a9a7ad27acb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80eb754c36ad4caa9a84e320fbbc6526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285d3bbe0fee4173a7643467e0f92187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2ce06e6e8864b18832d0cfa0ef3dcb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25b05837db304a2da5bffb35179adbfa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8d5ef5dfd5d47b2873ac64e425abb72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8111fee504ec43799395dc783d2069eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"E8_72-l0eBYC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e900e324-10bb-47e2-f4b8-791711de5141","executionInfo":{"status":"ok","timestamp":1750507928188,"user_tz":-180,"elapsed":22045,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install transformers==4.45.2 sentence-transformers==3.1.1 trl -U -q --quiet\n","!pip install -U bitsandbytes --quiet\n","!pip install datasets --quiet\n","!pip install gcsfs==2024.12.0  --quiet\n","!pip install fsspec==2024.12.0 --quiet\n","!pip install -q sacrebleu sacremoses --quiet\n","!pip install bert-score --quiet\n","!pip install evaluate --quiet"],"metadata":{"id":"VnAiHk61eDFH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750508118444,"user_tz":-180,"elapsed":116652,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"5be7cb29-0ee5-4327-cfe4-91aa505dd683"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# !pip install -U \"transformers==4.46.0\""],"metadata":{"id":"IiLlcyK0eDr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import login\n","# login('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')\n","# login('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')\n","login('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')"],"metadata":{"id":"BmhgEOWteM8R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wandb login 44cf8dda2faf2640928cf4a408e14138cb3477b2"],"metadata":{"id":"mReLJFqXeNcx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d56c372-534e-481a-f58b-0d3b6ce984b6","executionInfo":{"status":"ok","timestamp":1748631190328,"user_tz":-180,"elapsed":6381,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer,AutoModelForCausalLM\n","from peft import LoraConfig, get_peft_model, PeftModel\n","from transformers import BitsAndBytesConfig\n","from tqdm.auto import tqdm\n","import json\n","import random\n","import numpy as np\n","import time\n","from datasets import Dataset, load_dataset\n","import torch\n","import pandas as pd\n","import evaluate"],"metadata":{"id":"ZwdKhMNHC4A2","executionInfo":{"status":"ok","timestamp":1750514032836,"user_tz":-180,"elapsed":7876,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", torch_dtype=torch.float16, device_map=\"auto\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"],"metadata":{"id":"zYnL9faQHr_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"ContactDoctor/Bio-Medical-Llama-3-8B\",\n","              trust_remote_code=True)\n","base_id   = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n","domain_ckpt = \"/content/drive/MyDrive/NLP 1/Project/clef25_runs_new_last/checkpoint-890\"\n","base = AutoModelForCausalLM.from_pretrained(\n","    base_id, torch_dtype=torch.float16, device_map=\"auto\",offload_folder=\"./offload_dir\")\n","model = PeftModel.from_pretrained(base,domain_ckpt)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["52660196a8124f1d9e13976ad5ac4203","f218075168e84cd89cf889d755e165fd","da45140575304c03a00e3219caa2b839","be25ad12801b4eb4885d2843a9ff20d0","433a2d27dfbd43f98ee956180eb907ff","3ca93a8ae8c441d78fb35e2651fcd1c1","b7ef11b413724fa48f8d2d57f2f89738","fd8dd7f02dfa4b2f827a50893b26185c","3c150b96c7e54d0fa401889120ab74bf","efd76514580241e197971746100ad9ae","c16cdd17238c4e4c88915663be4f7d13","bf9ef4fd8cb341238fc1333d3d8198a8","c72a00f768ea45f89f86da180a9e062a","6ecafbda92ca4a46b68c22a07645af75","5d2d786cd2f544f0a86a839e696f8095","77eb3e9ec0d04eaa8384a98f2e5b773c","e9b3646327ad47559515e47d7191a5f0","e74e71ca920f4d6ab31391ba47169a9f","a241aaa04c9c4b94a67290c9593a1c7f","cf69a736909c4645b32a5f843bf5ec17","411e700675334403a6832ad79313bdb7","3af656ea00654e989dbe6628c6279631","bd18f0a6f2fa461cbfd2846f5febebf4","44c09ea8c5504d3f91bf62ea4736c3cd","586d0134598b4ca4956b84fd3fe0269a","1ed0d727852b4d2789a652c682561a29","88eda1e1bf174b36addf386eb4d4f544","682150ce061243b596474abd2113fb36","2d0f83fe885e4508ad2e761f91480462","41319df3a26d415ba15e8433e5a9bf4b","ec03fedf1a32455ba570c94050c3fd51","d061bdad50d24f24a3c7db25d4bfb804","b660452577dd4b229d365ff18548d774","6c4769cc973d47dc9234bc2d2de947e7","87d85c14cf194b42866d6073b4334fd3","bf8955c993fd4ff7babe6afb6b46f016","8868784d573742d7943f0e167e107e6e","4ef489c55c8e48a3b8473ccca4b7cc4e","be07c4ecd663421c94aaea2ee6a5ea4d","844f2eb29db047dd8e661832459f4f78","6ee3dc7bd5434de7b96ada01661702f4","ebfb21b3eebd46fbbf54989c74a1364f","9577ab32417144d88e2441ec9a9414f4","7c901dbaf9b64c68aaa038cddb2064f5","bd69d49269404e50a8527b0d9d696707","6f7ad5a881cf48f897619468f2f8f330","387979331eb4441787c2d8bf753fca15","c8122c2a122b43e1a884be8c1cba9146","c340e9a5da4c45ad93de86ec9472ef4c","befb6abb2cfd498bbbeebbc7a38b066f","5fcfc7a705614447af906108c2d7fade","5edbf390635e4935af195adf4f950649","fd9f2e5d15db4bc1bf86fc488d49d7de","c968f13e6898408fb253455af3a32b1f","10e004b7d41742178bf530f85ce00f31","286d7da9cf9447729160827ed4ee94ad","369e46356020459396242dd068df1b3b","b07259c855ce4034a5e600ef3fd9a8b2","52a16e828eb546d6af33830d7d2cb24f","e66e792b10dd4ccfb14eee2d175b9e98","f7fb6271d4b741a6b2befb67578632da","92aa4e8ca27a40a48f6f107657a570d1","366cf10bb030431cba77217be8c15083","1642ebb178d74e54b77714d8eefb1a61","3df3d10b9ce440c1b723a195922e45a8","f82d430b4fc14897a9fe8c6a75d5b0a1","294225166f0c41739d8fe17d58e9e455","38fefa4247b644c984377fb6a878c735","f31ce6650ab64490b638e1b675a996e8","1ef25d7ebd1e449786f2eb0558f84a03","7a088b7edbff4ab991269f41a4a3c070","a745cadaf74b466f90533d93419f3c41","5b993d9f84974e67b86504e9cf9b1cab","15e1be065b9747dd8bb859554db3f1fb","b3dcf676d85b4488bbf8bcb7e0a9f61c","8dc30708647d4547a9ef57fba81dedc0","0a041860dc96431d8a3fbdcf292704ad","443aee8d45104984bdf39a926f641c82","6547c57429d148e384a3ba8d47e3af35","86ae76fec0b148cc8c136373e62d416e","cde3a635f99a45d8a621188edf4702de","5da4035bfd7d4fe989e5a01cba922651","5d3207912adf42cdaf3d69f7d58e6dfe","2b934b9aa5f141da81ff3030e30fd0e3","5e608989d7e84bf9aa759785fa223d46","b3a24d4b05c5427ba2e672528a656cd2","06e98800d2b34c279ce761999d3ce154","6818cebe40d54e7e90fa1ad9ad9c1aa9","3dd80dbe6ce547ee9687f870cc9b298e","79495ca98d1b4583a0c6a23e08b68900","7b018da084504db68f60b2de70b6fd2e","b2f4be5871184cf4964533ccfb27f9c9","138493bcfab6421aa6ceed92c9880937","25d9cd7c72ed445692218b9c50e164af","8651af440faf4fc999f546d232940736","90625ecb8b1f47c48203207400b6bfaf","9cf5cbfc5737496d8edfd653f23e3831","db5feba79f14493c8bacc6766ad670d9","9a46de8476f24c1792bdd6cd2d7b73c5"]},"id":"Rb4hi2r8d6ju","outputId":"4250d687-39ee-4404-d7dc-e10c2dc82a60","executionInfo":{"status":"ok","timestamp":1748631303710,"user_tz":-180,"elapsed":94749,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/53.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52660196a8124f1d9e13976ad5ac4203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf9ef4fd8cb341238fc1333d3d8198a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd18f0a6f2fa461cbfd2846f5febebf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4769cc973d47dc9234bc2d2de947e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/22.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd69d49269404e50a8527b0d9d696707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286d7da9cf9447729160827ed4ee94ad"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"294225166f0c41739d8fe17d58e9e455"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/6.08G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443aee8d45104984bdf39a926f641c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dd80dbe6ce547ee9687f870cc9b298e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"]},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaSdpaAttention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["json_path = \"/content/drive/MyDrive/NLP 1/simpletext25_task12_test.json\"\n","# Load the test data\n","df = pd.read_json(json_path)\n","print(len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-TTZrIexLbO","executionInfo":{"status":"ok","timestamp":1748622732574,"user_tz":-180,"elapsed":437,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"3f0c1a9c-4990-41d3-aac5-a4e713414757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["666\n"]}]},{"cell_type":"code","source":["# json_path = \"/content/drive/MyDrive/NLP 1/simpletext25_task12_test.json\"\n","# # Load the test data\n","# df = pd.read_json(json_path)\n","# print(df.head())"],"metadata":{"id":"4-EnIrhAPlc4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt_sent = \"\"\"simplify complex medical sentences while preserving\n","# the main information and overall meaning:\n","# Replace specialized medical terms with simpler alternatives ->\n","# \"\"\"\n","prompt_sent = \"\"\"You are a skilled editor, known for your ability to simplify complex text while preserving its meaning. You have a strong understanding of readability principles and how to apply them to improve text comprehension, your output must be just simpliication .\"\"\"\n","\n","# prompt_sent = \"simplify next complex medical sentence while preserving the main information and overall meaning,Replace specialized medical terms with simpler alternatives\"\n","# prompt_sent = \"\"\"You are a skilled editor, known for your ability to simplify complex text while pre\n","# serving its meaning. You have a strong understanding of readability principles and\n","#  how to apply them to improve text comprehension.\"\"\"\n","propmt_doc = \"\"\"\n","Your task is to simplify complex medical documents while preserving\n"," the main information and overall meaning.Follow these guidelines:\n","Maintain the logical flow and relationships\n","   between sentences.- Identify sentences that can be merged for clarity without losing\n","    essential information.- Determine if any sentences can be removed without affecting\n","    the key message or context, Replace specialized medical terms\n","     with simpler alternatives\n","    Simplify next document\n","\n","\"\"\""],"metadata":{"id":"dbwsf0jTN9R1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.pad_token_id = tokenizer.eos_token_id"],"metadata":{"id":"92JDfzxsR2Gw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","tqdm.pandas()\n","\n","def simplify_batch(texts, batch_size=16):\n","    results = []\n","    for i in tqdm(range(0, len(texts), batch_size)):\n","      batch_texts = texts[i:i+batch_size]\n","      prompts = [\"Instruction: \"+prompt_sent +\" :\"+ text + \"\\nResponse:\" for text in batch_texts]\n","      # prompt = f\"{prompt_sent}:\\n{texts[i]}\\nSimplified:\"\n","\n","      inputs = tokenizer(prompts, return_tensors=\"pt\",padding = True,truncation=True, max_length= 1024).to(model.device)\n","      input_len = inputs[\"input_ids\"].shape[1]\n","      percentage = 0.9\n","\n","      max_new_tokens = int(input_len * percentage)\n","      max_new_tokens = max(1024, max_new_tokens)\n","      print(max_new_tokens)\n","      with torch.no_grad():\n","          outputs = model.generate(\n","              **inputs,\n","              max_new_tokens=max_new_tokens,\n","              do_sample=False,\n","              temperature= 0.2\n","          )\n","      decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","      simplified = [text.split(\"Simplified:\")[-1].strip() for text in decoded]\n","      results.extend(simplified)\n","    # result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    # # Remove the prompt prefix from the output\n","    # simplified = result.split(\"Simplified:\")[-1].strip()\n","    return results\n"],"metadata":{"id":"UWL8NlJGMlaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# link_df_val_sents= \"/content/drive/MyDrive/NLP 1/Project/data/cochraneauto_docs_val.csv\"\n","# df = pd.read_csv(link_df_val_sents)\n","# df"],"metadata":{"id":"a4LM2HVdt3Ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Apply the model to each sentence\n","complex_sentences = df[\"complex\"].tolist()\n","# simmp=simplify_batch(complex_sentences, batch_size=32)\n","\n","# x= (simplify_batch(complex_sentences, batch_size=4))\n","df[\"prediction\"] = simplify_batch(complex_sentences, batch_size=16)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2KhRBaGPjzA","executionInfo":{"status":"ok","timestamp":1748624739282,"user_tz":-180,"elapsed":2006666,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"03a5a8b2-773e-40ab-b400-046b38286ba7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","  2%|▏         | 1/42 [01:13<50:14, 73.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 2/42 [02:26<48:38, 72.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 3/42 [03:38<47:18, 72.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 4/42 [04:51<46:02, 72.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 5/42 [06:03<44:47, 72.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 6/42 [07:16<43:33, 72.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 7/42 [08:28<42:20, 72.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 8/42 [09:41<41:07, 72.56s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██▏       | 9/42 [10:53<39:53, 72.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 10/42 [12:06<38:40, 72.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 11/42 [13:18<37:27, 72.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▊       | 12/42 [14:31<36:15, 72.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 13/42 [15:43<35:02, 72.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 14/42 [16:56<33:50, 72.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 15/42 [17:33<27:47, 61.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 16/42 [18:14<24:06, 55.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 17/42 [18:31<18:22, 44.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 18/42 [19:11<17:05, 42.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 19/42 [19:49<15:54, 41.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 20/42 [20:32<15:20, 41.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 21/42 [21:10<14:14, 40.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 22/42 [22:18<16:15, 48.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 23/42 [23:05<15:17, 48.31s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 24/42 [23:46<13:51, 46.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 25/42 [24:54<14:55, 52.68s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 26/42 [25:34<13:01, 48.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 27/42 [26:11<11:21, 45.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 28/42 [27:22<12:23, 53.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 29/42 [28:31<12:31, 57.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████▏  | 30/42 [28:57<09:38, 48.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 31/42 [29:17<07:18, 39.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 32/42 [29:47<06:08, 36.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▊  | 33/42 [30:15<05:06, 34.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 34/42 [30:34<03:57, 29.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 35/42 [31:34<04:30, 38.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 36/42 [31:51<03:13, 32.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 37/42 [32:06<02:16, 27.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 38/42 [32:35<01:50, 27.68s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 39/42 [32:50<01:11, 23.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 40/42 [33:02<00:40, 20.20s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 41/42 [33:16<00:18, 18.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [33:26<00:00, 47.78s/it]\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"vvHTctqi8rYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complex_sentences[3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"8LzNFgVj4aGo","executionInfo":{"status":"ok","timestamp":1748614853298,"user_tz":-180,"elapsed":11,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"772fa988-eb67-4e3c-83e3-cd345928ea3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'This review included five RCTs with a total of 563 participants recruited from primary or tertiary care. Three trials were conducted in the USA, one in Australia, and one in Scotland. Three trials received financial support from non-commercial funders and two did not provide information on funding sources. All trials were at high risk of performance and detection bias. None of the included trials measured adverse events. McKenzie method versus minimal intervention (educational booklet; McKenzie method as a supplement to other intervention - main comparison)\\nThere is low-certainty evidence that the McKenzie method may result in a slight reduction in pain in the short term (MD -7.30, 95% CI -12.04 to -2.56; 2 trials, 328 participants) but not in the intermediate term (MD -5.00, 95% CI -14.29 to 4.29; 1 trial, 180 participants). There is low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD -2.74, 95% CI -7.52 to 2.04; 2 trials, 328 participants) nor in the intermediate term (MD -0.87, 95% CI -7.31 to 5.57; 1 trial, 180 participants). McKenzie method versus manual therapy\\nThere is low-certainty evidence that the McKenzie method may not reduce pain in the short term (MD -8.67, 95% CI -27.37 to 10.02; 3 trials, 298 participants) and may result in a slight increase in pain in the intermediate term (MD 7.00, 95% CI 0.70 to 13.30; 1 trial, 235 participants). There is low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD -4.98, 95% CI -15.00 to 5.04; 3 trials, 298 participants) nor in the intermediate term (MD 4.30, 95% CI -0.72 to 9.32; 1 trial, 235 participants). McKenzie method versus other interventions (massage and advice)\\nThere is very low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD 4.00, 95% CI -15.44 to 23.44; 1 trial, 30 participants) nor in the intermediate term (MD 10.00, 95% CI -8.95 to 28.95; 1 trial, 25 participants). Based on low- to very low-certainty evidence, the treatment effects for pain and disability found in our review were not clinically important. Thus, we can conclude that the McKenzie method is not an effective treatment for (sub)acute NSLBP.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["x = [s.split(\"Response:\")[-1] for s in x]\n"],"metadata":{"id":"uzYr6emkkVBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x[3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"17cjTMBYgTXg","executionInfo":{"status":"ok","timestamp":1748614862612,"user_tz":-180,"elapsed":20,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"98efd318-b193-4ca0-e80c-6f5b16bc725c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nThis review included five RCTs with a total of 563 participants recruited from primary or tertiary care. Three trials were conducted in the USA, one in Australia, and one in Scotland. Three trials received financial support from non-commercial funders and two did not provide information on funding sources. All trials were at high risk of performance and detection bias. None of the included trials measured adverse events. McKenzie method versus minimal intervention (educational booklet; McKenzie method as a supplement to other intervention - main comparison)\\nThere is low-certainty evidence that the McKenzie method may result in a slight reduction in pain in the short term (MD -7.30, 95% CI -12.04 to -2.56; 2 trials, 328 participants) but not in the intermediate term (MD -5.00, 95% CI -14.29 to 4.29; 1 trial, 180 participants). There is low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD -2.74, 95% CI -7.52 to 2.04; 2 trials, 328 participants) nor in the intermediate term (MD -0.87, 95% CI -7.31 to 5.57; 1 trial, 180 participants). McKenzie method versus manual therapy\\nThere is low-certainty evidence that the McKenzie method may not reduce pain in the short term (MD -8.67, 95% CI -27.37 to 10.02; 3 trials, 298 participants) and may result in a slight increase in pain in the intermediate term (MD 7.00, 95% CI 0.70 to 13.30; 1 trial, 235 participants). There is low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD -4.98, 95% CI -15.00 to 5.04; 3 trials, 298 participants) nor in the intermediate term (MD 4.30, 95% CI -0.72 to 9.32; 1 trial, 235 participants). McKenzie method versus other interventions (massage and advice)\\nThere is very low-certainty evidence that the McKenzie method may not reduce disability in the short term (MD 4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":[],"metadata":{"id":"9vBXNKaefuCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['prediction'].tolist()[55]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"RbwmgIRwxcNq","executionInfo":{"status":"ok","timestamp":1748558787811,"user_tz":-180,"elapsed":5,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"b3c5d825-98f7-43fc-aaaf-a1f0b916dcca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Instruction: You are a skilled editor, known for your ability to simplify complex text while preserving its meaning. You have a strong understanding of readability principles and how to apply them to improve text comprehension, your output must be just simpliication. :We included nine studies with 678 participants (80% females) with JIA. The mean age of participants ranged from 8 to 15 years, and the mean duration of symptoms ranged from 0.8 years to 6.7 years. Seven studies compared TNFi to placebo (570 participants), and two studies compared TNFi combined with MTX to MTX alone (108 participants). We identified no studies investigating the other predefined comparisons. Only two studies had a low risk of bias in all domains, while five studies had a high risk of bias in at least one domain, predominantly other bias. Two studies were at unclear risk of selection bias, and two studies were at unclear risk of detection bias. TNFi versus placebo\\nBenefits at up to 16 weeks\\nLow-certainty evidence (downgraded for risk of bias and imprecision) suggests that treatment with TNFi may increase the likelihood of achieving a treatment response, defined as pedACR70 (34% compared to 14% with placebo) (risk ratio [RR] 2.47, 95% confidence interval [CI] 1.48 to 4.14; 4 studies, 245 participants). The evidence is very uncertain (downgraded for indirectness and imprecision) for the effect of TNFi on pain, with mean pain scores (visual analogue scale [VAS] 0 to 100, 0 no pain, minimal clinically important difference [MCID] = 15 mm) lower with TNFi (11 mm) compared to placebo (33 mm) (mean difference [MD] 22 mm, 95% CI 50 mm lower to 5.7 mm higher; 2 studies, 72 participants). Similarly, the effect of TNFi on function (Childhood Health Assessment Questionnaire [CHAQ], 0 to 3, 0 normal function) and quality of life (global assessment of well-being, VAS 0 to 100 mm, 0 no disease activity) is very uncertain. Mean function was 0.84 with TNFi and 1 with placebo (MD 0.16 lower, 95% CI 0.39 lower to 0.06 higher; 3 studies, 194 participants; very low-certainty evidence, downgraded for risk of bias and imprecision). The mean participant global assessment of well-being was 23 mm with TNFi and 34 mm with placebo (MD 11 mm lower, 95% CI 23 mm lower to 1 mm higher; 3 studies, 194 participants; very low-certainty evidence, downgraded for indirectness, imprecision, and risk of bias). No study reported data on remission. Harms at any time\\nWe are uncertain about the effect of TNFi on withdrawals due to adverse events (3%) compared to placebo (1%) (RR 3.41, 95% CI 0.73 to 15.9; 6 studies, 448 participants). We are also uncertain about the effect of TNFi on serious adverse events (7%) compared to placebo (6%) (RR 1.09, 95% CI 0.53 to 2.22; 6 studies, 448 participants). The certainty of evidence was very low, downgraded for risk of bias and imprecision. TNFi plus MTX versus MTX alone\\nBenefits at 17 to 26 weeks\\nWe are uncertain about the effect of TNFi plus MTX on treatment response. Seventy per cent of participants receiving MTX and 90% receiving TNFi plus MTX achieved treatment response (RR 1.29, 95% CI 0.93 to 1.77; 1 study, 40 participants). We are also uncertain about the effect of TNFi plus MTX on remission. Five per cent of participants on MTX monotherapy and 40% on combination therapy were in remission (RR 8.00, 95% CI 1.10 to 58.19; 1 study, 40 participants). No study reported pain, function, or participant global assessment of well-being. Harms at any time\\nWe are uncertain about the effect of TNFi plus MTX on withdrawals due to adverse events and serious adverse events. Very low-certainty evidence from two studies shows that 2/53 participants (4%) receiving MTX alone and 3/55 (5%) receiving TNFi plus MTX withdrew due to adverse events (RR 1.31, 95% CI 0.18 to 9.82; 108 participants), and 5/53 (9%) receiving MTX alone and 0/55 receiving TNFi plus MTX reported serious adverse events (RR 0.00, 95% CI 0.00 to 0.99; 108 participants).'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["df['simple'].tolist()[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"eLN2CxSvx05v","executionInfo":{"status":"ok","timestamp":1748282871705,"user_tz":-180,"elapsed":28,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"f53a460b-2306-4e73-c361-a73fac6d7653"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"['We found 16 randomised controlled trials (studies where treatments are decided at random; these usually give the most reliable evidence about treatment effects) comparing glucocorticoids around the time of embryo implantation versus no glucocorticoids or placebo (dummy treatment), in 2232 couples undergoing IVF/ICSI.']\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["df['prediction'] = df['prediction'].str.split(r'Response:').str[-1]"],"metadata":{"id":"bhm66P-H4SY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complex_sentences[3]"],"metadata":{"id":"FrZp3RCpUwpQ","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1748088034776,"user_tz":-180,"elapsed":3,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"2f12d50d-95e8-41f8-e0b5-b87e603eddcd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Five trials compared a multifaceted implementation intervention to no intervention, two trials compared one multifaceted implementation intervention to another multifaceted implementation intervention.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["\n","# Add run_id\n","team_id = \"EngKh\"\n","task_id = \"task1.2\"\n","method_used = \"biomedical_llama3_with_domainAdaptation_and_prompts\"\n","df[\"run_id\"] = f\"{team_id}_{task_id}_{method_used}\""],"metadata":{"id":"9nQO93WsTT90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_path = f\"/content/drive/MyDrive/{team_id}_{task_id}_{method_used}_fianl.json\"\n","df.to_json(output_path, orient='records')\n","print(f\"Saved submission to {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4XtVLCfP9IY","executionInfo":{"status":"ok","timestamp":1748624739333,"user_tz":-180,"elapsed":33,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"b8b5007c-3654-4bce-ec79-17c093f3835d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved submission to /content/drive/MyDrive/EngKh_task1.2_biomedical_llama3_with_domainAdaptation_and_prompts_fianl.json\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":997},"id":"8GP9TK5_ePe4","executionInfo":{"status":"ok","timestamp":1748282897035,"user_tz":-180,"elapsed":54,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"0273f37d-fb26-4687-ed54-92610b2f33e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       pair_id  para_id  sent_id  \\\n","0     CD005996        0        0   \n","1     CD005996        0        1   \n","2     CD005996        0        2   \n","3     CD005996        0        3   \n","4     CD005996        0        4   \n","...        ...      ...      ...   \n","1692  CD007868        4       11   \n","1693  CD007868        5       12   \n","1694  CD007868        5       13   \n","1695  CD007868        5       14   \n","1696  CD007868        5       15   \n","\n","                                                complex     label  \\\n","0          We included 16 RCTs (2232 couples analysed).  rephrase   \n","1     We are uncertain whether glucocorticoids impro...  rephrase   \n","2     This suggests that if the chance of live birth...    ignore   \n","3     We are also uncertain whether there was a diff...  rephrase   \n","4     The I2 of 53% may represent moderate statistic...    delete   \n","...                                                 ...       ...   \n","1692  When reported, effects such as soft tissue dam...  rephrase   \n","1693  This Cochrane Review supports the benefits of ...  rephrase   \n","1694  Evidence for the effects of different fluoride...    delete   \n","1695  For many comparisons of different concentratio...  rephrase   \n","1696  The choice of fluoride toothpaste concentratio...    ignore   \n","\n","                                                 simple  simp_sent_id  \\\n","0     ['We found 16 randomised controlled trials (st...             0   \n","1     ['Considering the quality of evidence, we are ...             1   \n","2     ['The evidence suggests that if the chance of ...             2   \n","3     ['We are also uncertain whether there was a di...             3   \n","4                                                    []             4   \n","...                                                 ...           ...   \n","1692  ['Most studies did not measure harmful effects...             9   \n","1693  ['There are benefits of using fluoride toothpa...            10   \n","1694                                                 []            11   \n","1695  ['For many of the comparisons of different str...            11   \n","1696  ['The choice of fluoride toothpaste for young ...            12   \n","\n","       doc_pos  doc_quint  doc_len  \\\n","0     0.090909          1       11   \n","1     0.181818          1       11   \n","2     0.272727          2       11   \n","3     0.363636          2       11   \n","4     0.454545          3       11   \n","...        ...        ...      ...   \n","1692  0.750000          4       16   \n","1693  0.812500          5       16   \n","1694  0.875000          5       16   \n","1695  0.937500          5       16   \n","1696  1.000000          5       16   \n","\n","                                             prediction  \\\n","0     We included 16 randomised controlled trials (2...   \n","1     Glucocorticoids may not significantly improve ...   \n","2     This suggests that if the chance of live birth...   \n","3     We are also uncertain whether there was a diff...   \n","4     The I2 of 53% may represent moderate statistic...   \n","...                                                 ...   \n","1692  When reported, effects were minimal and includ...   \n","1693  This Cochrane Review confirms the benefits of ...   \n","1694  A. However, evidence for the effects of differ...   \n","1695  For many comparisons of different concentratio...   \n","1696  Instruction: You are a skilled editor, known f...   \n","\n","                                                 run_id  \n","0     EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","1     EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","2     EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","3     EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","4     EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","...                                                 ...  \n","1692  EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","1693  EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","1694  EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","1695  EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","1696  EngKh_task1.1_biomedical_llama3_with_domainAda...  \n","\n","[1697 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-d9146aff-9f88-4fe7-9bdc-fb92a30daf09\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pair_id</th>\n","      <th>para_id</th>\n","      <th>sent_id</th>\n","      <th>complex</th>\n","      <th>label</th>\n","      <th>simple</th>\n","      <th>simp_sent_id</th>\n","      <th>doc_pos</th>\n","      <th>doc_quint</th>\n","      <th>doc_len</th>\n","      <th>prediction</th>\n","      <th>run_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CD005996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>We included 16 RCTs (2232 couples analysed).</td>\n","      <td>rephrase</td>\n","      <td>['We found 16 randomised controlled trials (st...</td>\n","      <td>0</td>\n","      <td>0.090909</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>We included 16 randomised controlled trials (2...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CD005996</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>We are uncertain whether glucocorticoids impro...</td>\n","      <td>rephrase</td>\n","      <td>['Considering the quality of evidence, we are ...</td>\n","      <td>1</td>\n","      <td>0.181818</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>Glucocorticoids may not significantly improve ...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CD005996</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>This suggests that if the chance of live birth...</td>\n","      <td>ignore</td>\n","      <td>['The evidence suggests that if the chance of ...</td>\n","      <td>2</td>\n","      <td>0.272727</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>This suggests that if the chance of live birth...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CD005996</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>We are also uncertain whether there was a diff...</td>\n","      <td>rephrase</td>\n","      <td>['We are also uncertain whether there was a di...</td>\n","      <td>3</td>\n","      <td>0.363636</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>We are also uncertain whether there was a diff...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CD005996</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>The I2 of 53% may represent moderate statistic...</td>\n","      <td>delete</td>\n","      <td>[]</td>\n","      <td>4</td>\n","      <td>0.454545</td>\n","      <td>3</td>\n","      <td>11</td>\n","      <td>The I2 of 53% may represent moderate statistic...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1692</th>\n","      <td>CD007868</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>When reported, effects such as soft tissue dam...</td>\n","      <td>rephrase</td>\n","      <td>['Most studies did not measure harmful effects...</td>\n","      <td>9</td>\n","      <td>0.750000</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>When reported, effects were minimal and includ...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>1693</th>\n","      <td>CD007868</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>This Cochrane Review supports the benefits of ...</td>\n","      <td>rephrase</td>\n","      <td>['There are benefits of using fluoride toothpa...</td>\n","      <td>10</td>\n","      <td>0.812500</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>This Cochrane Review confirms the benefits of ...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>1694</th>\n","      <td>CD007868</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>Evidence for the effects of different fluoride...</td>\n","      <td>delete</td>\n","      <td>[]</td>\n","      <td>11</td>\n","      <td>0.875000</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>A. However, evidence for the effects of differ...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>1695</th>\n","      <td>CD007868</td>\n","      <td>5</td>\n","      <td>14</td>\n","      <td>For many comparisons of different concentratio...</td>\n","      <td>rephrase</td>\n","      <td>['For many of the comparisons of different str...</td>\n","      <td>11</td>\n","      <td>0.937500</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>For many comparisons of different concentratio...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","    <tr>\n","      <th>1696</th>\n","      <td>CD007868</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>The choice of fluoride toothpaste concentratio...</td>\n","      <td>ignore</td>\n","      <td>['The choice of fluoride toothpaste for young ...</td>\n","      <td>12</td>\n","      <td>1.000000</td>\n","      <td>5</td>\n","      <td>16</td>\n","      <td>Instruction: You are a skilled editor, known f...</td>\n","      <td>EngKh_task1.1_biomedical_llama3_with_domainAda...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1697 rows × 12 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9146aff-9f88-4fe7-9bdc-fb92a30daf09')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d9146aff-9f88-4fe7-9bdc-fb92a30daf09 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d9146aff-9f88-4fe7-9bdc-fb92a30daf09');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0c8d84b1-400e-4086-b845-052b0da292ed\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c8d84b1-400e-4086-b845-052b0da292ed')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0c8d84b1-400e-4086-b845-052b0da292ed button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_2553b7bd-adc5-4a11-b0ac-2110df15e44d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2553b7bd-adc5-4a11-b0ac-2110df15e44d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1697,\n  \"fields\": [\n    {\n      \"column\": \"pair_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 119,\n        \"samples\": [\n          \"CD001777\",\n          \"CD004507\",\n          \"CD006171\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"para_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          11,\n          9,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 35,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          35,\n          13,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"complex\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1695,\n        \"samples\": [\n          \"It decreases the cardiac output and increases the systemic vascular resistance.\",\n          \"Any future high-quality research should focus on determining whether particular groups of children benefit more from water precautions than others, as well as on developing clinical guidelines and their implementation.\",\n          \"Four trials (five articles) met the inclusion criteria of this review; three were RCTs and one was a quasi-RCT; and included a total of 280 participants treated in neonatal intensive care units in the UK.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"rephrase\",\n          \"ignore\",\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"simple\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1040,\n        \"samples\": [\n          \"['Three trials were funded by the hospitals were the trials took place and one trial was funded by the Scottish government.']\",\n          \"['We identified four studies including 141 participants; two of these were in children (aged six months to 14.5 years) and two did not specify the age of the participants.']\",\n          \"['Exercise versus uPEP\\\\nOne study (13 participants) compared exercise to uPEP (also known as bubble PEP).']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"simp_sent_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 24,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9,\n          16,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_pos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2882683682613782,\n        \"min\": 0.0277777777777777,\n        \"max\": 1.0,\n        \"num_unique_values\": 234,\n        \"samples\": [\n          0.6428571428571429,\n          0.5652173913043478,\n          0.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_quint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 5,\n        \"max\": 36,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          22,\n          15,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1651,\n        \"samples\": [\n          \"Please rephrase the sentence to make it more concise and easier to understand while maintaining its original meaning.\",\n          \"A. no\\nB. yes\\nC. maybe\",\n          \"Five studies compared titanium clips with ligature, two studies compared an endoscopic stapler device with ligature, and one study compared an endoscopic stapler device, titanium clips, and ligature.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"EngKh_task1.1_biomedical_llama3_with_domainAdaptation_and_prompts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["\n","\n","\n"],"metadata":{"id":"h5MjBZichyXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"8D5d7GdmrSKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"4MBtb8zXrStB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"oPPax0gYrTBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to your JSON file\n","json_path = '/content/drive/MyDrive/EngKh_task1.2_biomedical_llama3_with_domainAdaptation_and_prompts_fianl.json'\n","\n","# Load JSON into a DataFrame\n","df = pd.read_json(json_path)\n"],"metadata":{"id":"nr9JBDKlrTN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Lnqf6HvrrpXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Assuming columns are named 'original' and 'simplified'\n","original_texts = df['complex'].tolist()\n","simplified_texts = df['prediction'].tolist()"],"metadata":{"id":"XLak5rZ3rnjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","import numpy as np\n","\n","# Initialize BLEU scorer\n","bleu = BLEU()\n","\n","# Lists to store scores\n","sari_scores = []\n","bleu_scores = []\n","lens_scores = []\n","\n","for orig, simp in zip(original_texts, simplified_texts):\n","    # SARI: Use original as source and simplified as hypothesis, with original as reference\n","    sari = corpus_sari(\n","        orig_sents=[orig],\n","        sys_sents=[simp],\n","        refs_sents=[[orig]]  # Use original as reference if no other references\n","    )\n","    sari_scores.append(sari)\n","\n","    # BLEU: Compare simplified against original (or reference if available)\n","    bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","    bleu_scores.append(bleu_score)\n","\n","    # LENS: Length ratio (simplified length / original length)\n","    orig_len = len(orig.split())\n","    simp_len = len(simp.split())\n","    lens_score = simp_len / orig_len if orig_len > 0 else 0\n","    lens_scores.append(lens_score)\n","\n","# Compute average scores\n","avg_sari = np.mean(sari_scores)\n","avg_bleu = np.mean(bleu_scores)\n","avg_lens = np.mean(lens_scores)\n","\n","print(f\"Average SARI: {avg_sari:.2f}\")\n","print(f\"Average BLEU: {avg_bleu:.2f}\")\n","print(f\"Average LENS: {avg_lens:.2f}\")"],"metadata":{"id":"NSC9A4zki6Yr","executionInfo":{"status":"ok","timestamp":1748631337731,"user_tz":-180,"elapsed":4916,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"6d47a567-b136-40ec-c188-e0d44cdf46cc","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SARI: 13.24\n","Average BLEU: 27.46\n","Average LENS: 0.67\n"]}]},{"cell_type":"code","source":["!pip install nltk sacrebleu --quiet\n","!pip install git+https://github.com/feralvam/easse.git --quiet"],"metadata":{"id":"_8wT8mvbumRV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748631321696,"user_tz":-180,"elapsed":17211,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"0f3608f7-5e5e-4b8d-a0be-b3cdb0ff5f99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for easse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for tseval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for yattag (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","import numpy as np\n","\n","# Initialize BLEU scorer\n","bleu = BLEU()\n","\n","# Lists to store scores\n","sari_scores = []\n","bleu_scores = []\n","lens_scores = []\n","\n","for orig, simp in zip(original_texts, simplified_texts):\n","    # SARI: Use original as source and simplified as hypothesis, with original as reference\n","    sari = corpus_sari(\n","        orig_sents=[orig],\n","        sys_sents=[simp],\n","        refs_sents=[[orig]]  # Use original as reference if no other references\n","    )\n","    sari_scores.append(sari)\n","\n","    # BLEU: Compare simplified against original (or reference if available)\n","    bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","    bleu_scores.append(bleu_score)\n","\n","    # LENS: Length ratio (simplified length / original length)\n","    orig_len = len(orig.split())\n","    simp_len = len(simp.split())\n","    lens_score = simp_len / orig_len if orig_len > 0 else 0\n","    lens_scores.append(lens_score)\n","\n","# Compute average scores\n","avg_sari = np.mean(sari_scores)\n","avg_bleu = np.mean(bleu_scores)\n","avg_lens = np.mean(lens_scores)\n","\n","print(f\"Average SARI: {avg_sari:.2f}\")\n","print(f\"Average BLEU: {avg_bleu:.2f}\")\n","print(f\"Average LENS: {avg_lens:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTyUZOHdrok9","executionInfo":{"status":"ok","timestamp":1748344585739,"user_tz":-180,"elapsed":1479,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"6705501f-2a7e-46e4-9fea-1ce36acb79e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SARI: 32.78\n","Average BLEU: 66.74\n","Average LENS: 1.61\n"]}]},{"cell_type":"code","source":["\n","# Assuming columns are named 'original' and 'simplified'\n","original_texts = df['simple'].tolist()\n","simplified_texts = df['prediction'].tolist()"],"metadata":{"id":"6xqK2A2MddBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","import numpy as np\n","\n","# Initialize BLEU scorer\n","bleu = BLEU()\n","\n","# Lists to store scores\n","sari_scores = []\n","bleu_scores = []\n","lens_scores = []\n","\n","for orig, simp in zip(original_texts, simplified_texts):\n","    # SARI: Use original as source and simplified as hypothesis, with original as reference\n","    sari = corpus_sari(\n","        orig_sents=[orig],\n","        sys_sents=[simp],\n","        refs_sents=[[orig]]  # Use original as reference if no other references\n","    )\n","    sari_scores.append(sari)\n","\n","    # BLEU: Compare simplified against original (or reference if available)\n","    bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","    bleu_scores.append(bleu_score)\n","\n","    # LENS: Length ratio (simplified length / original length)\n","    orig_len = len(orig.split())\n","    simp_len = len(simp.split())\n","    lens_score = simp_len / orig_len if orig_len > 0 else 0\n","    lens_scores.append(lens_score)\n","\n","# Compute average scores\n","avg_sari = np.mean(sari_scores)\n","avg_bleu = np.mean(bleu_scores)\n","avg_lens = np.mean(lens_scores)\n","\n","print(f\"Average SARI: {avg_sari:.2f}\")\n","print(f\"Average BLEU: {avg_bleu:.2f}\")\n","print(f\"Average LENS: {avg_lens:.2f}\")"],"metadata":{"id":"YV_T4tADsABh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748344641416,"user_tz":-180,"elapsed":1112,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"fffa0e85-e0d1-4373-db71-0578f0193615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SARI: 20.39\n","Average BLEU: 16.63\n","Average LENS: 2.95\n"]}]},{"cell_type":"code","source":["\n","# Path to your JSON file\n","json_path = '/content/drive/MyDrive/EngKh_task1.1_biomedical_llama3_with_domainAdaptation_and_prompts_validation_sents.json'\n","\n","# Load JSON into a DataFrame\n","df = pd.read_json(json_path)\n","\n","# Assuming columns are named 'original' and 'simplified'\n","original_texts = df['complex'].tolist()\n","simplified_texts = df['prediction'].tolist()"],"metadata":{"id":"HEQC6AX7drzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","import numpy as np\n","\n","# Initialize BLEU scorer\n","bleu = BLEU()\n","\n","# Lists to store scores\n","sari_scores = []\n","bleu_scores = []\n","lens_scores = []\n","\n","for orig, simp in zip(original_texts, simplified_texts):\n","    # SARI: Use original as source and simplified as hypothesis, with original as reference\n","    sari = corpus_sari(\n","        orig_sents=[orig],\n","        sys_sents=[simp],\n","        refs_sents=[[orig]]  # Use original as reference if no other references\n","    )\n","    sari_scores.append(sari)\n","\n","    # BLEU: Compare simplified against original (or reference if available)\n","    bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","    bleu_scores.append(bleu_score)\n","\n","    # LENS: Length ratio (simplified length / original length)\n","    orig_len = len(orig.split())\n","    simp_len = len(simp.split())\n","    lens_score = simp_len / orig_len if orig_len > 0 else 0\n","    lens_scores.append(lens_score)\n","\n","# Compute average scores\n","avg_sari = np.mean(sari_scores)\n","avg_bleu = np.mean(bleu_scores)\n","avg_lens = np.mean(lens_scores)\n","\n","print(f\"Average SARI: {avg_sari:.2f}\")\n","print(f\"Average BLEU: {avg_bleu:.2f}\")\n","print(f\"Average LENS: {avg_lens:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWZkmzWPeQCz","executionInfo":{"status":"ok","timestamp":1748344841404,"user_tz":-180,"elapsed":2131,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"5e2a5734-5e96-4277-afd0-c1dbb7cac7a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SARI: 21.19\n","Average BLEU: 44.82\n","Average LENS: 1.24\n"]}]},{"cell_type":"code","source":["original_texts = df['simple'].tolist()\n","simplified_texts = df['prediction'].tolist()"],"metadata":{"id":"LFqXxp6jeSxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","from nltk.translate.bleu_score import sentence_bleu\n","import numpy as np\n","\n","# Initialize BLEU scorer\n","bleu = BLEU()\n","\n","# Lists to store scores\n","sari_scores = []\n","bleu_scores = []\n","lens_scores = []\n","\n","for orig, simp in zip(original_texts, simplified_texts):\n","    # SARI: Use original as source and simplified as hypothesis, with original as reference\n","    sari = corpus_sari(\n","        orig_sents=[orig],\n","        sys_sents=[simp],\n","        refs_sents=[[orig]]  # Use original as reference if no other references\n","    )\n","    sari_scores.append(sari)\n","\n","    # BLEU: Compare simplified against original (or reference if available)\n","    bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","    bleu_scores.append(bleu_score)\n","\n","    # LENS: Length ratio (simplified length / original length)\n","    orig_len = len(orig.split())\n","    simp_len = len(simp.split())\n","    lens_score = simp_len / orig_len if orig_len > 0 else 0\n","    lens_scores.append(lens_score)\n","\n","# Compute average scores\n","avg_sari = np.mean(sari_scores)\n","avg_bleu = np.mean(bleu_scores)\n","avg_lens = np.mean(lens_scores)\n","\n","print(f\"Average SARI: {avg_sari:.2f}\")\n","print(f\"Average BLEU: {avg_bleu:.2f}\")\n","print(f\"Average LENS: {avg_lens:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EatVEZqoeYcE","executionInfo":{"status":"ok","timestamp":1748344869943,"user_tz":-180,"elapsed":1455,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"2a1ecda2-f4dc-4a9a-cf8f-900e805b1a52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SARI: 6.71\n","Average BLEU: 9.50\n","Average LENS: 13.26\n"]}]},{"cell_type":"code","source":["original_texts[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xsDs3tN6sn7i","executionInfo":{"status":"ok","timestamp":1748344892474,"user_tz":-180,"elapsed":29,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"1972bc0a-f794-440c-a100-a73d90c81ad0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"['With regard to ongoing pregnancy and clinical pregnancy rates, we are also uncertain whether there was a difference between glucocorticoids versus no glucocorticoids or placebo.']\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":[],"metadata":{"id":"LL2UTpZFeXR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["simplified_texts[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"QR0A3jt-svM7","executionInfo":{"status":"ok","timestamp":1748344896465,"user_tz":-180,"elapsed":18,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"aa8d8ba6-6e80-40ee-c38d-3e44f07d9010"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Pregnancy rates after using glucocorticoids for ovarian hyperstimulation syndrome (OHSS) are uncertain. Compared to no glucocorticoids or a placebo, ongoing pregnancy rates did not appear to be significantly different (OR 1.19, 95% CI 0.80 to 1.76; 3 studies, 476 participants; very low-certainty evidence). Similarly, clinical pregnancy rates did not seem to be significantly affected (OR 1.17,'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTaNQ9j_5Kj2","executionInfo":{"status":"ok","timestamp":1748082658772,"user_tz":-180,"elapsed":18664,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"6dc0d860-45be-4084-ff15-c7a4677d131f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for easse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for tseval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for yattag (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","from easse.sari import corpus_sari\n","from sacrebleu.metrics import BLEU\n","import numpy as np\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","from tqdm import tqdm\n","# Path to your JSON file\n","json_path = '/content/drive/MyDrive/NLP 1/Project/EngKh_task1.1_biomedical_llama3_with_domainAdaptation_and_prompts.json'\n","\n","# Load JSON into a DataFrame\n","df = pd.read_json(json_path)\n","\n","# Load original Llama-3-8B\n","original_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3-8B\", torch_dtype=torch.float16, device_map=\"auto\")\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-8B\")\n","\n","# Load fine-tuned Bio-Medical-Llama-3-8B (already loaded in your code)\n","# Assume fine_tuned_model is your Bio-Medical-Llama-3-8B\n","# fine_tuned_model=  AutoModelForCausalLM.from_pretrained(\"ContactDoctor/Bio-Medical-Llama-3-8B\", torch_dtype=torch.float16, device_map=\"auto\")\n","# tokenizer_fine = AutoTokenizer.from_pretrained(\"ContactDoctor/Bio-Medical-Llama-3-8B\")\n","\n","\n","\n"],"metadata":{"id":"JPyzfTLRubg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_sent = \"simplify next complex medical sentence while preserving the main information and overall meaning,Replace specialized medical terms with simpler alternatives\"\n","def evaluate_model(model, texts, prompt_template,tokenizer):\n","    sari_scores, bleu_scores, lens_scores = [], [], []\n","    simpp , org = [] , []\n","    bleu = BLEU()\n","    for orig in tqdm(texts,desc=\"processing\"):\n","        org.append(orig)\n","        # Generate simplified\n","        prompt = prompt_template + orig + \"\\nSimplified:\"\n","        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n","        with torch.no_grad():\n","            outputs = model.generate(**inputs, max_new_tokens=256, do_sample=False, temperature=0.2)\n","        simp = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Simplified:\")[-1].strip()\n","        simpp.append(simp)\n","        # Metrics\n","        sari = corpus_sari(orig_sents=[orig], sys_sents=[simp], refs_sents=[[orig]])\n","        bleu_score = bleu.corpus_score([simp], [[orig]]).score\n","        lens = len(word_tokenize(simp)) / len(word_tokenize(orig)) if len(word_tokenize(orig)) > 0 else 0\n","        sari_scores.append(sari)\n","        bleu_scores.append(bleu_score)\n","        lens_scores.append(lens)\n","    return np.mean(sari_scores), np.mean(bleu_scores), np.mean(lens_scores), org, simpp"],"metadata":{"id":"WGFLrc4CqVoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","# Evaluate both models\n","test_texts = df['complex'].tolist()[:2]  # Subset for efficiency\n","# orig_sari, orig_bleu, orig_lens = evaluate_model(original_model, test_texts, prompt_sent,tokenizer)\n","fine_sari, fine_bleu, fine_lens, org,simpp = evaluate_model(model, test_texts, prompt_sent,tokenizer)\n","\n","# print(f\"Original Llama-3-8B: SARI={orig_sari:.2f}, BLEU={orig_bleu:.2f}, LENS={orig_lens:.2f}\")\n","print(f\"Fine-tuned Bio-Medical-Llama-3-8B: SARI={fine_sari:.2f}, BLEU={fine_bleu:.2f}, LENS={fine_lens:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8RCDcUX8thf","outputId":"9511b8e9-5155-4996-89e1-5efe725fe6bd","executionInfo":{"status":"ok","timestamp":1748083048459,"user_tz":-180,"elapsed":27104,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","processing:   0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","processing:  50%|█████     | 1/2 [00:13<00:13, 13.72s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","processing: 100%|██████████| 2/2 [00:27<00:00, 13.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Fine-tuned Bio-Medical-Llama-3-8B: SARI=2.36, BLEU=0.66, LENS=4.65\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["print(org[1])\n"],"metadata":{"id":"fRgFgwJbqdTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748083070345,"user_tz":-180,"elapsed":5,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"60aae413-c9d6-4eab-fdc7-b851bfdf0228"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Health professional participants (numbers not specified) included nursing, medical and allied health professionals.\n"]}]},{"cell_type":"code","source":["print(f\"Fine-tuned Bio-Medical-Llama-3-8B: SARI={fine_sari:.2f}, BLEU={fine_bleu:.2f}, LENS={fine_lens:.2f}\")\n"],"metadata":{"id":"KPIufM7c5WK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748083048478,"user_tz":-180,"elapsed":5,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"88b1296a-b661-430e-9fe1-305ede7f8403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fine-tuned Bio-Medical-Llama-3-8B: SARI=2.36, BLEU=0.66, LENS=4.65\n"]}]},{"cell_type":"code","source":["print(simpp)\n"],"metadata":{"id":"axN-WvadrEza","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748083048501,"user_tz":-180,"elapsed":22,"user":{"displayName":"NLP 1","userId":"15968334851302319565"}},"outputId":"b27afd53-b809-42cd-add7-69bb787c21b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,', '\"The patient should be given a low dose of a long-acting beta-agonist, such as salmeterol, and a short-acting beta-agonist, such as albuterol, as needed.\" Original: \"The patient should be given a low dose of a long-acting beta-agonist,']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2g72wB5jp1tL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"ContactDoctor/Bio-Medical-Llama-3-8B\",\n","              trust_remote_code=True)\n","base_id   = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n","domain_ckpt = \"/content/drive/MyDrive/NLP 1/Project/clef25_runs_new_last/checkpoint-890\"\n","base = AutoModelForCausalLM.from_pretrained(\n","    base_id, torch_dtype=torch.float16, device_map=\"auto\",offload_folder=\"./offload_dir\")\n","model = PeftModel.from_pretrained(base,domain_ckpt)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f79f12d7e0914c2fbbfb59b2683dae96","c3963e87a4ee41c6bb2a62353ba7622e","75477a0564204d198d87337df62b3043","8e254fc381e04813ab8be452db42da5b","ed337bcfcacd4caa8cb85742e44ff02d","4e1a20112bed46578369d886e2b6dc89","b755f66d312744d88a3901f12cf3ab5e","29cba5d235b94f0a83ca93c50cbe145b","41f44a11dc2d41488936ddf87720b2d9","1a802a8d831f4a179a9210935d2103d8","065521a754d64da6b12fbb75004e5163","a69b8dcf416541a69d9460e8486777e1","64d24888e4b94dc9bf059cf8be0f754e","4bc14f59137e41369d29027adbe40df4","3f0589fd486646c2aa59e115604d56c7","4e5349e35db843b3aa08a7670dc8fd73","a963878ebf1a42a5bd49b78c25aab78b","5bb4d21fb63a43ec989cf073b5fe554e","3718144bec7a424d823b012f01ca7e60","0e90a3dfa9624ab9b5fc18359bb0931b","9d2b1a6400b34ed9b6be0e41faa0e426","231d0b572d274f0980adf12bab460a49","da588342ae6d410e928a0520ac918abe","2d5ab4fdfb4f48af95ae22ec5e4b2da5","1df1182331194beea1ab852ce3f08cfc","54df150386f24d2ea7bd7f3c26c5008d","c12182951c934c5b9af34f2017e0a8d1","15140c13777e43008a3715cb10cb2f9d","3b4262b22f4b4e058bfebc7dd04bdfff","976ddb009c2d4314a0efce740c1e610a","a47a237689d24d3fbe517ccf2ca6c794","553837e9363242bab9bb42c41967aadb","dc66de4a5ef546ee871d1cb17cd5af17","7be0c3f848bf4b5cb9e3ac4dded5de64","c5d2ac39bb74479db8030ef28008c8eb","0637f625cd34418dbb24f2dcadfaefa2","b262a4271ba749bdafa02f8760a5623a","94242b72504341a59116f50ca9e2ef8c","c2b95f8e5dcf44008246d50b291bb0c6","fbbf9ec9cca64a509c8bbdbdd5ed8367","2e989990463b4139a5029cbfd0c9bd89","91fcf4301b3b4ecbb3f01424e2b36d04","452e6f2d1e6a49ed9f77c9ab4d669d92","ddeaf3fef16749b3b973911ad8c9ada0","641ff5c9a46c4e41bb85a543561c085c","bf7f4f945c0a423da5ac4d435751b49f","7f6e77420bc14879afc7386960b84186","c48fdcf895bb4c87afc1cbf46bc36ba0","495c78c7bf514e929a56636cee56e0c4","03c032865c3049f0b287fd4fc5e1092d","1896cd889335437f9464145a709bf927","5f973ad7145a4c5295e75c69723a4d62","7d49be462fda443197cd91dca7019bfe","742c7f91fb424b9d8206f87b6bd8fce0","bbb32f53e0f2434fb18274efd1ef3088","411fccda502c4dd5937bca93dee3641e","28e3c5a752ba4febbfb94cfd2603a9b2","503c21dc84f34ab9af5edc3e2c690378","a0e444ba8a8c436cbe1bf4aded24c4ae","092946569b094270ad534c0038948378","a5d3ffe492024e28a2122e63df527e47","111f2e7bc141402f9a4ca03682a057c8","3b7277cb733c4f2794f17fe91333f562","c00cfbc38a5246b38cbfae0ba9bd0ac6","dc26085621a949c1a2e7cb4c68571340","98759d876df94393a8fdb48205d219df","a9ade09c1df84f5bad5f4b9f099fbfbc","0a888f0c73ac4e9d835219a6b56da733","80d54a8125034b6a8165b31cca4efbfe","c10f86cae96141eeb4dbd0313b6743ec","5656341b0c1a477981ed6cb75639c78d","6df8c32f9e2442d0bbad2a0ee853ddad","60f34ad15540476a8880c980c9176bd6","cc3ed82d34464c7e9af47a7cd50fb4fd","33ad4602552a4f8bbdcca983d77e9dd5","6727b49957ce45f9ad15fd8c9419a195","2ce27d00e21240008a9e18e0825946db","6dde1519a07941f88619f8c845af6398","d0ffe4220f8b4ef1a3ec5cf147825df6","19369f65a55e4d2f82dac1b1a2409927","4dd50c98cd014c6a8526d3957d020302","cfa35fc61a3d4e5caf60371b48ff13b9","7472237b2e684932a437a02b1d7a29c4","00c0dda3f1a14c68a88cdf54fa66aaf8","78c72825e78745a788e856c8b72dc1a2","4070b5394dac41298735b0b2d58dbbc3","2bfb5732b8d84dd39c423d3208c62aa3","f9f74ed447ee4bebb0877e6a2704a901","fec843c0f3ee45cda278f5e2a60bd0bb","54898c91bc664da2a4863a6965b883d8","7ccc05ecaeb4402ca30254dbd8bef4f8","fed139af239b4bb1aa38a0791406f5c2","7205ac3943e4428da06f4d43f27fc943","98d4bebb64274aa7982ec515de34b50a","0c4f3a82b36d4b80a19fefea4f0ad215","ea1270e9e5b24b82a5763b4fbd1162ea","f63189ec65a5447a968ec5f3b522aa90","a49c0b9d8b894554ad21dc25dad0011b","3d7645d20377489586b09a6b1d53fe4e"]},"id":"O1Bhgtpxe6Vf","executionInfo":{"status":"ok","timestamp":1750509497977,"user_tz":-180,"elapsed":98357,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"cde22415-d8b4-44bd-82d2-4bc8c6e48beb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/53.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f79f12d7e0914c2fbbfb59b2683dae96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a69b8dcf416541a69d9460e8486777e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da588342ae6d410e928a0520ac918abe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be0c3f848bf4b5cb9e3ac4dded5de64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/22.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"641ff5c9a46c4e41bb85a543561c085c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"411fccda502c4dd5937bca93dee3641e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ade09c1df84f5bad5f4b9f099fbfbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/6.08G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dde1519a07941f88619f8c845af6398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec843c0f3ee45cda278f5e2a60bd0bb"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaSdpaAttention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["SENTS_PATH = \"/content/drive/MyDrive/NLP 1/Project/data/cochraneauto_sents_val.csv\"\n","DOCS_PATH  = \"/content/drive/MyDrive/NLP 1/Project/data/cochrane_docs_val.csv\""],"metadata":{"id":"Ia-IxIiFe6_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_sents = pd.read_csv(SENTS_PATH)\n","df_docs  = pd.read_csv(DOCS_PATH)"],"metadata":{"id":"64uBpJ7dfjUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","\n","def generate_batch(texts, max_new=128, bs=4):\n","    outs = []\n","    for i in tqdm(range(0, len(texts), bs)):\n","        batch = texts[i:i+bs]\n","        inputs = tokenizer(batch, return_tensors=\"pt\",\n","                           padding=True, truncation=True).to(model.device)\n","        with torch.no_grad():\n","            gen = model.generate(\n","                    **inputs,\n","                    max_new_tokens=max_new,\n","                    do_sample=False,\n","                    num_beams=4,\n","                    early_stopping=True)\n","        outs += tokenizer.batch_decode(gen, skip_special_tokens=True)\n","        del inputs, gen\n","        torch.cuda.empty_cache()\n","    return outs\n","\n","df_sents[\"prediction\"] = generate_batch(df_sents[\"complex\"].tolist(), max_new=80, bs=8)\n","df_docs[\"prediction\"]  = generate_batch(df_docs[\"complex\"].tolist(), max_new=256, bs=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c0b07a8e234d4ee3a6d627efa946b780","baf153bc8a5846b39c1176dd86bdf61b","0c52aab46c7242fb80277ec0138ca628","551390bb37c0469988b6cbfdd797fb3f","59a0f2548e364a12967b32caec063b4f","4f948c01627d48b890ad649932fd81a4","1a5510b4b8ae45bcb63af12e89c5df2e","bd3502af869b4a3aa3242bfa78de67d8","fadd944a29a64f4b86f7a9a7e2eeed99","2ee44a9552d742e997004c15f5663e8f","1b44621528984cf993fcfec79e7a85cc","956ff30ca6c74d29b2b6c32685293c06","2ad8626f9da0459fb3db85fe6790922e","f53a5e3022104af5b19c03909fac56b4","8e41acc15294491999db3c0792dc7b1c","2c7de76c7cac453cb1a056df04905ef5","b6b430360e4b41f688e300d11d9c4c7c","8c71f6cdd87e4788a99f2fa10f996c3f","3f58b09eba9f456d8272015870eb8864","dfb3670a13fb42cc9d1b1f523329e406","0dc1c0aff4d34badb78e0ffdd84bf034","4974e882e0d34a2496548e1a71e8d7c7"]},"id":"KawWHLUCfbrC","executionInfo":{"status":"error","timestamp":1750511491995,"user_tz":-180,"elapsed":1810805,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"5f58e49c-f944-4a8f-8f17-b1192728c4f4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/213 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b07a8e234d4ee3a6d627efa946b780"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/250 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"956ff30ca6c74d29b2b6c32685293c06"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-10-515931487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdf_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-10-515931487.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(texts, max_new, bs)\u001b[0m\n\u001b[1;32m      8\u001b[0m                            padding=True, truncation=True).to(model.device)\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             gen = model.generate(\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m             \u001b[0;31m# 13. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2079\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 )\n\u001b[1;32m    999\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1001\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dora\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_adapter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlora_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from evaluate import load\n","import sacrebleu\n","\n","sari   = load(\"sari\")\n","bleu   = sacrebleu.metrics.BLEU()\n","\n","def eval_sentence_level(df):\n","    sari_score = sari.compute(\n","        sources      = df[\"complex\"].tolist(),\n","        predictions  = df[\"prediction\"].tolist(),\n","        references   = [[x] for x in df[\"simple\"].tolist()])[\"sari\"]\n","    bleu_score = bleu.corpus_score(\n","        df[\"prediction\"].tolist(),\n","        [df[\"simple\"].tolist()]).score\n","    lens = {\n","        \"complex_tok_avg\" : df[\"complex\"].apply(lambda x: len(tokenizer.tokenize(x))).mean(),\n","        \"pred_tok_avg\"    : df[\"prediction\"].apply(lambda x: len(tokenizer.tokenize(x))).mean(),\n","        \"simple_tok_avg\"  : df[\"simple\"].apply(lambda x: len(tokenizer.tokenize(x))).mean()\n","    }\n","    return sari_score, bleu_score, lens\n","\n","sari_s, bleu_s, lens_s = eval_sentence_level(df_sents)\n","print(f\"Sentence-level  SARI={sari_s:.2f}  BLEU={bleu_s:.2f}\\nLengths: {lens_s}\")"],"metadata":{"id":"KalMh87Ofzeo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/RLSNLP/Document-level-text-simplification/main/D_SARI.py\n","from D_SARI import document_sari   # simple wrapper\n","\n","def eval_doc_level(df):\n","    sari_score = document_sari(\n","        df[\"complex\"].tolist(),\n","        df[\"prediction\"].tolist(),\n","        df[\"simple\"].tolist())\n","    bleu_score = bleu.corpus_score(\n","        df[\"prediction\"].tolist(),\n","        [df[\"simple\"].tolist()]).score\n","    return sari_score, bleu_score\n","\n","sari_d, bleu_d = eval_doc_level(df_docs)\n","print(f\"Document-level  D-SARI={sari_d:.2f}  BLEU={bleu_d:.2f}\")"],"metadata":{"id":"m8gcFor8gHNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Rp5aA43BhoNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"693JUI4yiNu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, gc, os\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel\n","\n","BASE_ID = \"ContactDoctor/Bio-Medical-Llama-3-8B\"\n","DOMAIN_CKPT = \"/content/drive/MyDrive/NLP 1/Project/clef25_runs_new_last/checkpoint-890\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(BASE_ID, trust_remote_code=True)\n","base      = AutoModelForCausalLM.from_pretrained(\n","               BASE_ID,\n","               torch_dtype=torch.float16,\n","               device_map=\"auto\",\n","               offload_folder=\"./offload_dir\")\n","model     = PeftModel.from_pretrained(base, DOMAIN_CKPT)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ec9442077ad34917a884992411bdecd3","93fbbc99b2f34df4a008d65704c46e6a","498ab8e53e9d4b4b9cb041be82e51345","f221879e61044262b53969e283974453","3edbabc9d37143f7a9e22783740e29b7","76b7f51246524517956d23441b7763e7","c745a752867c4fc49830b762e6ea9f8c","286bf0d22fe0443fb6a08661abfb4ecb","40a274f6a4294d2b9918c234f265d6f3","fae36d7ac8444e5dab5e62bb92cae25b","7ba8ec8871574e9292ca67fcb13f2c06"]},"id":"kMqAd0j2iOF3","executionInfo":{"status":"ok","timestamp":1750514044527,"user_tz":-180,"elapsed":10591,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"af5a633c-f3f9-4a0b-d3c6-8b34002148e5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9442077ad34917a884992411bdecd3"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaSdpaAttention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.1, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# ---------- Sentence-level ----------\n","PROMPT_SENT_PRE = \"\"\"### Instruction:\n","Simplify the following medical sentence for a general reader. \\\n","Preserve all facts; do NOT add commentary.\n","\n","### Input:\n","<complex>\n","\"\"\"\n","PROMPT_SENT_POST = \"\"\"\n","</complex>\n","\n","### Output:\n","\"\"\"\n","\n","def wrap_sent(text: str) -> str:\n","    return f\"{PROMPT_SENT_PRE}{text}{PROMPT_SENT_POST}\"\n","\n","# ---------- Document-level ----------\n","PROMPT_DOC_PRE = \"\"\"### Instruction:\n","Simplify the medical document below for a lay audience.\n"," • Keep logical flow.\n"," • Merge sentences only when it improves clarity.\n"," • Remove redundant sentences.\n"," • Replace specialised terms with plain-language synonyms.\n","Return ONLY the simplified document.\n","\n","### Input:\n","<complex>\n","\"\"\"\n","PROMPT_DOC_POST = \"\"\"\n","</complex>\n","\n","### Output:\n","\"\"\"\n","\n","def wrap_doc(text: str) -> str:\n","    return f\"{PROMPT_DOC_PRE}{text}{PROMPT_DOC_POST}\""],"metadata":{"id":"S_YZr_JGiOpU","executionInfo":{"status":"ok","timestamp":1750514044546,"user_tz":-180,"elapsed":17,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","SENTS_PATH = \"/content/drive/MyDrive/NLP 1/Project/data/cochraneauto_sents_val.csv\"\n","DOCS_PATH  = \"/content/drive/MyDrive/NLP 1/Project/data/cochrane_docs_val.csv\"\n","\n","df_sents = pd.read_csv(SENTS_PATH)   # expects: id,complex,simple\n","df_docs  = pd.read_csv(DOCS_PATH)    # expects: id,complex,simple"],"metadata":{"id":"txV0zQGIiU3y","executionInfo":{"status":"ok","timestamp":1750514044602,"user_tz":-180,"elapsed":45,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ----------\n","CTX_WINDOW = 8192            # hard limit for Llama-3-8B   [Meta spec]\n","HARD_CAP   = 1024            # never request more than this\n","RATIO      = 0.9             # 90 % of prompt length (sent-level best-practice)\n","\n","def pick_max_new(input_len: int,\n","                 ratio: float = RATIO,\n","                 hard_cap: int = HARD_CAP,\n","                 ctx_window: int = CTX_WINDOW) -> int:\n","    \"\"\"\n","    Compute a safe max_new_tokens value:\n","      • proportional to input_len (ratio)\n","      • never larger than remaining context_window\n","      • never larger than hard_cap\n","    \"\"\"\n","    remaining = max(ctx_window - input_len, 1)\n","    target    = round(input_len * ratio)\n","    return min(target, remaining, hard_cap)"],"metadata":{"id":"40m4fqQHwW6w","executionInfo":{"status":"ok","timestamp":1750514044635,"user_tz":-180,"elapsed":1,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# from tqdm.auto import tqdm\n","\n","# def generate_batch(texts, wrap_fn, max_new=128, bs=4):\n","#     outs = []\n","#     for i in tqdm(range(0, len(texts), bs)):\n","#         batch = [wrap_fn(t) for t in texts[i:i+bs]]\n","#         inputs = tokenizer(batch, return_tensors=\"pt\",\n","#                            padding=True, truncation=True).to(model.device)\n","#         with torch.no_grad():\n","#             gen = model.generate(\n","#                     **inputs,\n","#                     max_new_tokens=max_new,\n","#                     do_sample=False,\n","#                     num_beams=4,\n","#                     early_stopping=True)\n","#         outs += tokenizer.batch_decode(gen, skip_special_tokens=True)\n","#         del inputs, gen\n","#         gc.collect(); torch.cuda.empty_cache()\n","#     return outs\n","\n","# # --- run inference ---\n","# df_sents[\"prediction\"] = generate_batch(\n","#         df_sents[\"complex\"].tolist(),\n","#         wrap_fn = wrap_sent,\n","#         max_new = 80,\n","#         bs      = 8)\n","\n","# df_docs[\"prediction\"]  = generate_batch(\n","#         df_docs[\"complex\"].tolist(),\n","#         wrap_fn = wrap_doc,\n","#         max_new = 256,\n","#         bs      = 2)\n","from tqdm.auto import tqdm\n","import torch, gc\n","\n","def generate_batch(\n","        texts,\n","        wrap_fn,\n","        bs            = 4,\n","        sync_gpu      = True,\n","        clear_cache_n = 50\n","    ):\n","    \"\"\"\n","    Prompt-aware generation with dynamic max_new_tokens.\n","    \"\"\"\n","    outs   = []\n","    device = model.device\n","    pbar   = tqdm(total=len(texts), desc=\"⇢ generating\")\n","\n","    for start in range(0, len(texts), bs):\n","        batch_txt = [wrap_fn(t) for t in texts[start:start + bs]]\n","\n","        tokens = tokenizer(batch_txt,\n","                           return_tensors=\"pt\",\n","                           padding=True,\n","                           truncation=True,\n","                           max_length=CTX_WINDOW\n","                          ).to(device)\n","\n","        # --- dynamic length -------------------------------------------------\n","        inp_len       = tokens[\"input_ids\"].shape[1]           # longest in batch\n","        max_new       = pick_max_new(inp_len)                  # <<<< new line\n","\n","        with torch.no_grad():\n","            gen_ids = model.generate(\n","                **tokens,\n","                max_new_tokens = max_new,\n","                num_beams      = 4,\n","                do_sample      = False,\n","                early_stopping = True\n","            )\n","\n","        if sync_gpu:\n","            torch.cuda.synchronize()                          # wait for GPU :contentReference[oaicite:6]{index=6}\n","\n","        outs.extend(tokenizer.batch_decode(gen_ids, skip_special_tokens=True))\n","\n","        # housekeeping -------------------------------------------------------\n","        del tokens, gen_ids\n","        if clear_cache_n and (start // bs + 1) % clear_cache_n == 0:\n","            torch.cuda.empty_cache()                          # heavy call; throttle :contentReference[oaicite:7]{index=7}\n","        gc.collect()\n","        pbar.update(len(batch_txt))\n","\n","    pbar.close()\n","    return outs\n"],"metadata":{"id":"wlvhYGjjiYjD","executionInfo":{"status":"ok","timestamp":1750514044703,"user_tz":-180,"elapsed":43,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ydsc33XMwVC2","executionInfo":{"status":"ok","timestamp":1750514045641,"user_tz":-180,"elapsed":2,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# --- run inference ---\n","df_sents[\"prediction\"] = generate_batch(\n","        df_sents[\"complex\"].tolist(),\n","        wrap_fn = wrap_sent,\n","        bs      = 8)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ea2b0267d09a4aecb863a1803b0f2daa","cd8242d77c2547a285e8a0cc1a9bf35f","6b524d5df3d04d01ac984122fbd1a039","6ee60c4fb94946719594a1a62eba1013","080b0d44533b4c00bfb7a8b19daac6fd","1d9e2ab4394c47048a90442f76379e46","24ebe58e3c114f6e932db33396bf526c","22aeea56a4784868b43d2346370507cb","86e67f26730e49689457f0c0e95d0974","6bbe445291b44fa7b206ed3284545839","889434f0d28e4011b9f492d12c17aebc"]},"id":"4oiB4hAzwHSO","executionInfo":{"status":"ok","timestamp":1750514896600,"user_tz":-180,"elapsed":850751,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"c615f9ff-1f46-46ed-d073-5272836c7e9d"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["⇢ generating:   0%|          | 0/1697 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea2b0267d09a4aecb863a1803b0f2daa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]}]},{"cell_type":"code","source":["df_docs[\"prediction\"]  = generate_batch(\n","        df_docs[\"complex\"].tolist(),\n","        wrap_fn = wrap_doc,\n","        bs      = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0788dd9dbd5644a8b8d6e81036a8a875","5e3e6c2b8ac14193a5353dcfe9adf8ba","3133e7a7776d43dfa2dd0bd9bcf05304","3dc8bdbafeba4a72913a87dc13e72410","816604c6ffdf46d2b0509a9a7ad27acb","80eb754c36ad4caa9a84e320fbbc6526","285d3bbe0fee4173a7643467e0f92187","a2ce06e6e8864b18832d0cfa0ef3dcb5","25b05837db304a2da5bffb35179adbfa","d8d5ef5dfd5d47b2873ac64e425abb72","8111fee504ec43799395dc783d2069eb"]},"id":"NXM2ETqixBVu","executionInfo":{"status":"error","timestamp":1750516932290,"user_tz":-180,"elapsed":2035679,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"9a122b55-dcea-464b-eedc-48f9f3d0b5d5"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["⇢ generating:   0%|          | 0/500 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0788dd9dbd5644a8b8d6e81036a8a875"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-8-1124210984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df_docs[\"prediction\"]  = generate_batch(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mdf_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mwrap_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         bs      = 2)\n","\u001b[0;32m/tmp/ipython-input-6-3156259288.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(texts, wrap_fn, bs, sync_gpu, clear_cache_n)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             gen_ids = model.generate(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mmax_new_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m             \u001b[0;31m# 13. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2079\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3313\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3314\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   3315\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3316\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mbatch_beam_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;31m# add to generated hypotheses if end of sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meos_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;31m# if beam_token does not belong to top num_beams tokens, it should not be added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0mis_beam_token_worse_than_top_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_token_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         if isinstance(\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSymInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSymBool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         ):\n","\u001b[0;32m/usr/lib/python3.11/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from evaluate import load\n","import sacrebleu\n","\n","sari = load(\"sari\")                         # HF Evaluate\n","bleu = sacrebleu.metrics.BLEU()             # OO-API\n","\n","def eval_sentence_level(df):\n","    sari_score = sari.compute(\n","        sources     = df[\"complex\"].tolist(),\n","        predictions = df[\"prediction\"].tolist(),\n","        references  = [[x] for x in df[\"simple\"].tolist()])[\"sari\"]\n","    bleu_score = bleu.corpus_score(\n","        df[\"prediction\"].tolist(),\n","        [df[\"simple\"].tolist()]).score\n","    lens = {\n","        \"complex_tok_avg\": df[\"complex\"].apply(lambda x: len(tokenizer.tokenize(x))).mean(),\n","        \"pred_tok_avg\"   : df[\"prediction\"].apply(lambda x: len(tokenizer.tokenize(x))).mean(),\n","        \"simple_tok_avg\" : df[\"simple\"].apply(lambda x: len(tokenizer.tokenize(x))).mean()\n","    }\n","    return sari_score, bleu_score, lens\n","\n","sari_s, bleu_s, lens_s = eval_sentence_level(df_sents)\n","print(f\"Sentence-level  SARI={sari_s:.2f}  BLEU={bleu_s:.2f}\")\n","print(lens_s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssHY8icJih11","executionInfo":{"status":"ok","timestamp":1750516941398,"user_tz":-180,"elapsed":3726,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"7e73cb3b-3d7f-4cce-f97d-f51ef35d1b7e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence-level  SARI=43.72  BLEU=6.40\n","{'complex_tok_avg': np.float64(35.76075427224514), 'pred_tok_avg': np.float64(97.44431349440188), 'simple_tok_avg': np.float64(19.281673541543903)}\n"]}]},{"cell_type":"code","source":["!pip install -q nltk\n","!wget -q -O D_SARI.py https://raw.githubusercontent.com/RLSNLP/Document-level-text-simplification/main/D_SARI.py"],"metadata":{"id":"GfZ7gkynsdJd","executionInfo":{"status":"ok","timestamp":1750513580977,"user_tz":-180,"elapsed":4224,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import importlib.util, pathlib, nltk, math, gc\n","nltk.download('punkt')  # needed for sent_tokenize inside D_SARI\n","\n","# --- load D_SARI dynamically ---\n","spec = importlib.util.spec_from_file_location(\"d_sari_mod\", \"D_SARI.py\")\n","d_sari_mod = importlib.util.module_from_spec(spec)\n","spec.loader.exec_module(d_sari_mod)\n","\n","# expose the sentence-level scorer\n","D_SARIsent = d_sari_mod.D_SARIsent\n","\n","def document_sari(sources, predictions, references):\n","    \"\"\"\n","    Compute D-SARI for a *list* of documents.\n","      sources      : list[str]\n","      predictions  : list[str]\n","      references   : list[str]  (or list[list[str]] if multi-ref)\n","    Returns the average D-SARI score.\n","    \"\"\"\n","    scores = []\n","    for src, pred, ref in zip(sources, predictions, references):\n","        # allow either 1 reference string or a list of refs\n","        ref_list = ref if isinstance(ref, list) else [ref]\n","        score, *_ = D_SARIsent(src, pred, ref_list)\n","        scores.append(score)\n","    return sum(scores) / len(scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jU3uAMFDseXM","executionInfo":{"status":"ok","timestamp":1750513602175,"user_tz":-180,"elapsed":480,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"73a18cff-9415-4863-d487-cd730ea5ccfe"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["def eval_doc_level(df):\n","    sari_score = document_sari(\n","            df_docs[\"complex\"].tolist(),\n","            df_docs[\"prediction\"].tolist(),\n","            df_docs[\"simple\"].tolist())\n","    bleu_score = bleu.corpus_score(\n","            df_docs[\"prediction\"].tolist(),\n","            [df_docs[\"simple\"].tolist()]).score\n","    return sari_score, bleu_score\n","\n","sari_d, bleu_d = eval_doc_level(df_docs)\n","print(f\"Document-level  D-SARI={sari_d:.2f}  BLEU={bleu_d:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"jciU07ywil1s","executionInfo":{"status":"error","timestamp":1750513615249,"user_tz":-180,"elapsed":108,"user":{"displayName":"Youssef Hani","userId":"17833260672490879595"}},"outputId":"7c6f5efa-e605-4dd8-95e0-ff097fc9ecc5"},"execution_count":20,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'prediction'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'prediction'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-20-1022806937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msari_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msari_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_doc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Document-level  D-SARI={sari_d:.2f}  BLEU={bleu_d:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-20-1022806937.py\u001b[0m in \u001b[0;36meval_doc_level\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m     sari_score = document_sari(\n\u001b[1;32m      3\u001b[0m             \u001b[0mdf_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"complex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mdf_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             df_docs[\"simple\"].tolist())\n\u001b[1;32m      6\u001b[0m     bleu_score = bleu.corpus_score(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'prediction'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P7N-SSs-ng-F"},"execution_count":null,"outputs":[]}]}